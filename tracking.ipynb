{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configparser import ConfigParser\n",
    "import cv2\n",
    "import errno\n",
    "import logging\n",
    "import os\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from random import randint\n",
    "from skimage.measure import compare_ssim\n",
    "import sys\n",
    "from statistics import mean\n",
    "import unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## constants ##\n",
    "\n",
    "SEQUENCE_PATH = \"MOT20/train/MOT20-01/\"\n",
    "CONFIG_FILENAME = \"seqinfo.ini\"\n",
    "DETECTIONS_DIR = \"det\"\n",
    "DETECTIONS_FILENAME = \"det.txt\"\n",
    "\n",
    "# this should be read from a config\n",
    "SEARCH_AREA = 200\n",
    "# DISTANCE_THRESHOLD = 0.1\n",
    "SIMILARITY_THRESHOLD = 0.24\n",
    "MEMORY_WINDOW = 30\n",
    "\n",
    "SSIM_MEAN = 0.25\n",
    "SIFT_MEAN = 0.025\n",
    "SURF_MEAN = 0.07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## logging ##\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "out_hdlr = logging.StreamHandler(sys.stdout)\n",
    "out_hdlr.setFormatter(logging.Formatter('%(asctime)s %(message)s'))\n",
    "out_hdlr.setLevel(logging.DEBUG)\n",
    "log.addHandler(out_hdlr)\n",
    "log.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tools(object):\n",
    "    \n",
    "    class Similarity(object):\n",
    "        \n",
    "        class Spatial(object):\n",
    "            \n",
    "            @staticmethod\n",
    "            def euclidean(det_a, det_b):\n",
    "                \n",
    "                center_a = det_a.centroid\n",
    "                center_b = det_b.centroid\n",
    "                \n",
    "                distance = math.sqrt(\n",
    "                    (center_b.x-center_a.x)**2 + (center_b.y-center_a.y)**2\n",
    "                )\n",
    "                \n",
    "                return distance                \n",
    "        \n",
    "            @staticmethod\n",
    "            def iou(det_a, det_b):\n",
    "\n",
    "                # to make this easier we'll create two arrays, [x1, y1, x2, y2], s.t.\n",
    "                # (x1, y1) is the top left point for a box and (x2, y2) is the bottom right\n",
    "                a = [det_a.x, det_a.y, det_a.x + det_a.w, det_a.y + det_a.h]\n",
    "                b = [det_b.x, det_b.y, det_b.x + det_b.w, det_b.y + det_b.h]\n",
    "\n",
    "                # intersection\n",
    "\n",
    "                # find the boundary of the intersection between the two boxes\n",
    "                x1 = max(a[0], b[0]) # rightmost x of the top left points\n",
    "                y1 = max(a[1], b[1]) # lowest y of the top left points\n",
    "                x2 = min(a[2], b[2]) # leftmost x of the bottom right points\n",
    "                y2 = min(a[3], b[3]) # highest y of the bottom right points\n",
    "\n",
    "                # find the area of the intersection\n",
    "                width = (x2 - x1)\n",
    "                height = (y2 - y1)\n",
    "\n",
    "                # if no overlap don't bother going further, return 0\n",
    "                if width <= 0 or height <= 0:\n",
    "                    return 0\n",
    "\n",
    "                area_of_intersection = width * height\n",
    "\n",
    "                # area of union\n",
    "\n",
    "                # this is easy, you don't need to know where the boxes are, since you've\n",
    "                # already calculated the intersection. if you just add the total area\n",
    "                # of box_a and the the area of box_b you've counted the intersection\n",
    "                # twice, so just subtract the intersection once and you have the answer\n",
    "                a_area = (a[2] - a[0]) * (a[3] - a[1])\n",
    "                b_area = (b[2] - b[0]) * (b[3] - b[1])\n",
    "\n",
    "                area_of_union = a_area + b_area - area_of_intersection\n",
    "\n",
    "                # protect again division by zero\n",
    "                epsilon = 1e-5\n",
    "\n",
    "                iou = area_of_intersection / (area_of_union + epsilon)\n",
    "                return iou\n",
    "\n",
    "        class Visual(object):\n",
    "        \n",
    "            @staticmethod\n",
    "            def ssim(det_a, det_b):\n",
    "                \n",
    "#                 patch_a = det_a.patch\n",
    "#                 patch_b = det_b.patch\n",
    "                \n",
    "                patch_a = det_a.eq_gray\n",
    "                patch_b = det_b.eq_gray\n",
    "\n",
    "                if patch_a.size > patch_b.size:\n",
    "                    h, w = patch_a.shape[0], patch_a.shape[1]\n",
    "                else:\n",
    "                    h, w = patch_b.shape[0], patch_b.shape[1]\n",
    "\n",
    "                patch_a_scaled = cv2.resize(\n",
    "                    patch_a, (w, h), interpolation=cv2.INTER_AREA)\n",
    "                patch_b_scaled = cv2.resize(\n",
    "                    patch_b, (w, h), interpolation=cv2.INTER_AREA)                            \n",
    "                \n",
    "                score, diff = compare_ssim(patch_a_scaled, patch_b_scaled, full=True, multichannel=True)\n",
    "\n",
    "                return score\n",
    "            \n",
    "            @staticmethod\n",
    "            def sift(det_a, det_b):\n",
    "                \n",
    "                patch_a = det_a.patch\n",
    "                patch_b = det_b.patch\n",
    "\n",
    "#                 gray_a = cv2.cvtColor(patch_a, cv2.COLOR_BGR2GRAY)\n",
    "#                 gray_b = cv2.cvtColor(patch_b, cv2.COLOR_BGR2GRAY)\n",
    "                \n",
    "                sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "                keypoints_a, descriptors_a = sift.detectAndCompute(patch_a, None)\n",
    "                keypoints_b, descriptors_b = sift.detectAndCompute(patch_b, None)\n",
    "\n",
    "#                 keypoints_a, descriptors_a = sift.detectAndCompute(gray_a, None)        \n",
    "#                 keypoints_b, descriptors_b = sift.detectAndCompute(gray_b, None)\n",
    "        \n",
    "                # FLANN feature matcher\n",
    "                \n",
    "                FLANN_INDEX_KDTREE = 0\n",
    "                index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "                search_params = dict(checks=50)   # or pass empty dictionary\n",
    "\n",
    "                flann = cv2.FlannBasedMatcher(index_params,search_params)\n",
    "                \n",
    "                try:\n",
    "                    matches = flann.knnMatch(descriptors_a, descriptors_b, k=2)\n",
    "                except Exception as ex:\n",
    "                    return 0\n",
    "\n",
    "                good_matches = []\n",
    "\n",
    "                # ratio test as per Lowe's paper\n",
    "                for i,(m,n) in enumerate(matches):\n",
    "                    if m.distance < 0.7*n.distance:\n",
    "                        good_matches.append(m)\n",
    "\n",
    "                epsilon = 1e-5\n",
    "\n",
    "                try:\n",
    "                    return len(good_matches) / (len(matches)+epsilon)\n",
    "                except Exception as ex:\n",
    "                    print(ex)\n",
    "                    return 0\n",
    "    \n",
    "            @staticmethod\n",
    "            def surf(det_a, det_b):\n",
    "                \n",
    "                patch_a = det_a.patch\n",
    "                patch_b = det_b.patch\n",
    "\n",
    "#                 gray_a = cv2.cvtColor(patch_a, cv2.COLOR_BGR2GRAY)\n",
    "#                 gray_b = cv2.cvtColor(patch_b, cv2.COLOR_BGR2GRAY)\n",
    "                \n",
    "                surf = cv2.xfeatures2d.SURF_create()\n",
    "\n",
    "                keypoints_a, descriptors_a = surf.detectAndCompute(patch_a, None)\n",
    "                keypoints_b, descriptors_b = surf.detectAndCompute(patch_b, None)\n",
    "\n",
    "#                 keypoints_a, descriptors_a = sift.detectAndCompute(gray_a, None)        \n",
    "#                 keypoints_b, descriptors_b = sift.detectAndCompute(gray_b, None)\n",
    "        \n",
    "                # FLANN feature matcher\n",
    "                \n",
    "                FLANN_INDEX_KDTREE = 0\n",
    "                index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "                search_params = dict(checks=50)   # or pass empty dictionary\n",
    "\n",
    "                flann = cv2.FlannBasedMatcher(index_params,search_params)\n",
    "                \n",
    "                try:\n",
    "                    matches = flann.knnMatch(descriptors_a, descriptors_b, k=2)\n",
    "                except Exception as ex:\n",
    "                    return 0\n",
    "\n",
    "                good_matches = []\n",
    "\n",
    "                # ratio test as per Lowe's paper\n",
    "                for i,(m,n) in enumerate(matches):\n",
    "                    if m.distance < 0.7*n.distance:\n",
    "                        good_matches.append(m)\n",
    "\n",
    "                epsilon = 1e-5\n",
    "\n",
    "                try:\n",
    "                    return len(good_matches) / (len(matches)+epsilon)\n",
    "                except Exception as ex:\n",
    "                    print(ex)\n",
    "                    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequence(object):\n",
    "    \n",
    "    ## Point ##\n",
    "    \n",
    "    class Point(object):\n",
    "        def __init__(self, x, y):\n",
    "            self.x = x\n",
    "            self.y = y\n",
    "    \n",
    "    ## ImageInfo ##\n",
    "    \n",
    "    class ImageInfo(object):\n",
    "        def __init__(self, img_dir, filename, height, width):\n",
    "            self.img_dir = img_dir\n",
    "            self.filename = filename\n",
    "            self.path = os.path.join(img_dir, filename)\n",
    "            self.frame_id = int('.'.join(filename.split('.')[:-1]))\n",
    "            self.height = height\n",
    "            self.width = width\n",
    "\n",
    "        def __str__(self):\n",
    "            return \"Frame: %s\\tHeight: %s\\t Width: %s\" % (\n",
    "                self.frame_id, self.height, self.width\n",
    "            )\n",
    "\n",
    "        def __repr__(self):\n",
    "            return \"ImageInfo(%s, %s, %s, %s)\" % (\n",
    "                self.img_dir, self.filename, self.height, self.width\n",
    "            )\n",
    "    \n",
    "    ## Detection ##\n",
    "    \n",
    "    class Detection(object):\n",
    "        def __init__(self, index, frame_id, track, x, y, w, h, confidence, patch=None, eq_gray=None):\n",
    "            self.index = index\n",
    "            self.frame = frame_id\n",
    "            self.trajectory = track\n",
    "            self.x = x\n",
    "            self.y = y\n",
    "            self.w = w\n",
    "            self.h = h\n",
    "            self.confidence = confidence\n",
    "            self.patch = patch\n",
    "            self.eq_gray = eq_gray\n",
    "\n",
    "        @property\n",
    "        def centroid(self):\n",
    "            return Sequence.Point(self.x+0.5*self.w, self.y+0.5*self.h)\n",
    "\n",
    "        def __str__(self):\n",
    "            return \"Index: %s, Frame: %s, Track: %s, x: %s, y: %s, w: %s, h: %s, conf: %s\" % (\n",
    "                self.index, self.frame, self.trajectory, self.x, self.y, \n",
    "                self.w, self.h, self.confidence\n",
    "            )\n",
    "\n",
    "        def __repr__(self):\n",
    "            return \"Detection(%s, %s,%s,%s,%s,%s,%s,%s)\" % (\n",
    "                self.index, self.frame, self.trajectory, self.x, self.y, \n",
    "                self.w, self.h, self.confidence\n",
    "            )\n",
    "    \n",
    "    ## Frame ##\n",
    "    \n",
    "    class Frame(object):\n",
    "        def __init__(self, index, image_info, image=None, detections=None):\n",
    "            self.index = index\n",
    "            self.image_info = image_info\n",
    "            self.image = image\n",
    "            self.detections = detections\n",
    "        \n",
    "        def __str__(self):\n",
    "            if self.detections:\n",
    "                return \"%s, detection count: %s\" % (self.image_info, len(self.detections))\n",
    "            else:\n",
    "                return \"%s\" % self.image_info\n",
    "\n",
    "        def __repr__(self):\n",
    "            return \"Frame(%s)\" % self.image_info\n",
    "    \n",
    "    ## Sequence ##\n",
    "    \n",
    "    def __init__(self, sequence_path, config_filename, detections_dir=None, detections_filename=None):\n",
    "        self.root_path = sequence_path\n",
    "        self.config_filename = config_filename\n",
    "        self.config_path = os.path.join(sequence_path, config_filename)\n",
    "        self.detecitons_path = None\n",
    "        self.name = None\n",
    "        self.length = None\n",
    "        self.frame_rate = None\n",
    "        self.height = None\n",
    "        self.width = None\n",
    "        self.image_path = None\n",
    "        self._image_infos = None\n",
    "        self._pos = None\n",
    "        self._load_conf()\n",
    "        self._load_image_infos()\n",
    "        self._detections = None\n",
    "        self._tracks = None\n",
    "        \n",
    "        # attributes of questionable value\n",
    "        self._mean_width = None\n",
    "        self._mean_height = None\n",
    "        \n",
    "        if detections_dir and detections_filename:\n",
    "            self.detections_path = os.path.join(\n",
    "                sequence_path, detections_dir, detections_filename\n",
    "            )\n",
    "            self._load_detections()\n",
    "        else:\n",
    "            log.info(\"No detections specified, loading only images.\")\n",
    "\n",
    "    def _load_conf(self):\n",
    "        \n",
    "        log.info(\"Loading sequence configuration.\")\n",
    "        \n",
    "        if not os.path.isfile(self.config_path):\n",
    "            raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT), self.config_path)\n",
    "        \n",
    "        config = ConfigParser()\n",
    "        config.read(self.config_path)\n",
    "        sequence_config = dict(config['Sequence'])\n",
    "        \n",
    "        self.name = sequence_config['name']\n",
    "        self.length = int(sequence_config['seqlength'])\n",
    "        self.frame_rate = sequence_config['framerate']\n",
    "        self.height = sequence_config['imheight']\n",
    "        self.width = sequence_config['imwidth']\n",
    "        self.image_path = os.path.join(self.root_path, sequence_config['imdir'])\n",
    "        self.image_ext = sequence_config['imext'].replace('.','')\n",
    "        \n",
    "    def _load_image_infos(self):\n",
    "        \n",
    "        log.info(\"Loading image info.\")\n",
    "        \n",
    "        dir_contents = os.listdir(self.image_path)\n",
    "        file_type = self.image_ext\n",
    "        image_infos = [Sequence.ImageInfo(self.image_path, x, self.height, self.width) \n",
    "                       for x in dir_contents if x.split('.')[-1] == file_type]\n",
    "        \n",
    "        image_infos.sort(key=lambda x: x.frame_id)\n",
    "        \n",
    "        if len(image_infos) != self.length:\n",
    "            msg = (\"The sequence length: %s, and image count: %s, do not match.\" % (\n",
    "                len(image_infos),\n",
    "                self.length\n",
    "            ))\n",
    "            log.debug(msg)\n",
    "        \n",
    "        self._image_infos = image_infos\n",
    "\n",
    "    def _load_detections(self):\n",
    "        \n",
    "        log.info(\"Loading detections.\")\n",
    "        \n",
    "        if not os.path.isfile(self.detections_path):\n",
    "            raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT), self.detections_path)\n",
    "\n",
    "        header_list = ['frame','trajectory','x','y','w','h','confidence', 'gt', 'class', 'vis']\n",
    "        index_col = []# ['frame','trajectory']\n",
    "        usecols = ['frame','trajectory','x','y','w','h','confidence']\n",
    "        dtype = {'frame':int,'trajectory':int,'x':float,'y':float,'w':float,'h':float,'confidence':float}\n",
    "        \n",
    "        df = pd.read_csv(\n",
    "            self.detections_path,\n",
    "            names = header_list,\n",
    "            index_col = index_col,\n",
    "            usecols = usecols,\n",
    "            dtype = dtype\n",
    "        )\n",
    "\n",
    "        # detections have confidence either 0 or 1, i'm not going to attempt\n",
    "        # to track low confidence detections at this time\n",
    "        # df = df[df[\"confidence\"] == 1]\n",
    "        \n",
    "        self._mean_width = df[\"w\"].mean()\n",
    "        self._mean_height = df[\"h\"].mean()\n",
    "        \n",
    "        start = df['frame'].min()\n",
    "        end = df['frame'].max()\n",
    "        \n",
    "        ## note ##  ##  ##  ##  ##  ##  ##  ##  ##  ##  ##  ##  ##  ##  ##\n",
    "        #                                                                #\n",
    "        #  i'm really not sure the best way to handle detections, for    #\n",
    "        #  now i'm just pulling rows out of the dataframe and creating   #\n",
    "        #  a dictionary of lists of detection objects                    #\n",
    "        #                                                                #\n",
    "        #  it might make more sense to keep them in a dataframe, perhaps #\n",
    "        #  to more efficiently query or apply offsets later              #\n",
    "        #                                                                #\n",
    "        ##  ##  ##  ##  ##  ##  ##  ##  ##  ##  ##  ##  ##  ##  ##  ##  ##\n",
    "        \n",
    "        self._detections = dict()\n",
    "        \n",
    "        for i in range(start, end+1):\n",
    "            frame = df[df['frame']==i]\n",
    "            detections = []\n",
    "            \n",
    "            for i, detection in frame.iterrows():                \n",
    "                frame_no, traj_no, x, y, w, h, conf = detection\n",
    "                \n",
    "                detections.append(\n",
    "                    Sequence.Detection(\n",
    "                        index=i,\n",
    "                        frame_id=int(frame_no), \n",
    "                        track=int(traj_no), \n",
    "                        x=int(round(x)),\n",
    "                        y=int(round(y)),\n",
    "                        w=int(round(w)),\n",
    "                        h=int(round(h)), \n",
    "                        confidence=conf\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            self._detections[int(frame_no)] = detections\n",
    "            \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        return self.next()\n",
    "    \n",
    "    def next(self):\n",
    "        while True:\n",
    "            if self._pos is None:\n",
    "                self._pos = 0\n",
    "            elif self._pos < len(self._image_infos):\n",
    "                current, self._pos = self._pos, self._pos + 1\n",
    "                current_info = self._image_infos[current]\n",
    "                frame_id = current_info.frame_id\n",
    "\n",
    "                image = None\n",
    "                \n",
    "                try:\n",
    "                    image = cv2.imread(current_info.path)\n",
    "                except Exception as ex:\n",
    "                    log.debug(ex)\n",
    "                                    \n",
    "                current_frame_detections = None\n",
    "                \n",
    "                if self._detections:\n",
    "                    \n",
    "                    if frame_id in self._detections.keys():\n",
    "                        current_frame_detections = self._detections[frame_id]\n",
    "                        if image is not None:\n",
    "                            for i, detection in enumerate(current_frame_detections):\n",
    "                                x1 = detection.x\n",
    "                                y1 = detection.y\n",
    "                                x2 = x1 + detection.w\n",
    "                                y2 = y1 + detection.h\n",
    "                                \n",
    "                                patch = image[y1:y2, x1:x2]\n",
    "                                current_frame_detections[i].patch = patch\n",
    "                                                                \n",
    "                                gray = cv2.cvtColor(patch, cv2.COLOR_BGR2GRAY)\n",
    "                                eq_gray = cv2.equalizeHist(gray)\n",
    "                \n",
    "                                current_frame_detections[i].eq_gray = eq_gray\n",
    "                \n",
    "                current_frame = Sequence.Frame(\n",
    "                    frame_id, current_info, image, current_frame_detections\n",
    "                )\n",
    "                \n",
    "                return current_frame\n",
    "            else:\n",
    "                raise StopIteration()\n",
    "\n",
    "    def __str__(self):\n",
    "        return(\"Sequence: %s\\nPath: %s\\nImage Path: %s\\nResolution: %sx%s\\nFrame Rate: %s\\nLength: %s\\nType: %s\"\n",
    "          % (\n",
    "              self.name,\n",
    "              self.root_path,              \n",
    "              self.image_path,\n",
    "              self.width,\n",
    "              self.height,\n",
    "              self.frame_rate,\n",
    "              self.length,\n",
    "              self.image_ext\n",
    "          ))\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return(\"Sequence(%s, %s)\" % (\n",
    "            self.root_path,\n",
    "            self.config_filename\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def track(sequence):\n",
    "    \n",
    "    spatial_measure = Tools.Similarity.Spatial.euclidean\n",
    "    # spatial_measure = Tools.Similarity.Spatial.iou\n",
    "    \n",
    "    # visual_measure = Tools.Similarity.Visual.ssim\n",
    "    visual_measure = Tools.Similarity.Visual.sift\n",
    "\n",
    "    track_counter = 1\n",
    "    previous_frame = None    \n",
    "    \n",
    "    # this should be read from a config\n",
    "    search_area = SEARCH_AREA\n",
    "    similarity_threshold = SIMILARITY_THRESHOLD\n",
    "    # distance_threshold = DISTANCE_THRESHOLD\n",
    "    memory_window = MEMORY_WINDOW\n",
    "    \n",
    "    ssim_mean = SSIM_MEAN\n",
    "    sift_mean = SIFT_MEAN\n",
    "    surf_mean = SURF_MEAN\n",
    "    \n",
    "    log.info(\"Calculating trajectories.\")\n",
    "    \n",
    "#     ssim_scores = [0.4]*5\n",
    "#     sift_scores = [0.15]*5\n",
    "#     surf_scores = [0.15]*5\n",
    "    \n",
    "    for current_frame in sequence:\n",
    "        \n",
    "        if previous_frame is None:    \n",
    "        \n",
    "            sequence._tracks = dict()\n",
    "        \n",
    "            # initialize trajectories to all detections in the first frame\n",
    "            for detection in current_frame.detections:\n",
    "                detection.trajectory = track_counter\n",
    "                sequence._tracks[track_counter] = [detection]\n",
    "                track_counter += 1\n",
    "\n",
    "            # no memory here\n",
    "            previous_frame = current_frame\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            completed_set = []\n",
    "            \n",
    "            sim_ranking = []\n",
    "            this_pair = None\n",
    "            \n",
    "            tracks = sequence._tracks\n",
    "            track_ids = list(tracks.keys())\n",
    "            tails = [tracks[k][-1] for k in track_ids]\n",
    "            active_tails = [tail for tail in tails if (current_frame.index - tail.frame) <= memory_window]\n",
    "            \n",
    "            for det_a in active_tails: # previous_frame.detections:\n",
    "                for det_b in current_frame.detections:                    \n",
    "                    this_pair = set([det_a.index, det_b.index])\n",
    "                    \n",
    "                    if this_pair not in completed_set:                    \n",
    "                        dist = spatial_measure(det_a, det_b)                        \n",
    "                        completed_set.append(this_pair)\n",
    "                        \n",
    "                        if dist <= search_area:\n",
    "                            # score = visual_measure(det_a, det_b)\n",
    "                            \n",
    "                            ssim_score = Tools.Similarity.Visual.ssim(det_a, det_b)\n",
    "                            sift_score = Tools.Similarity.Visual.sift(det_a, det_b)\n",
    "                            surf_score = Tools.Similarity.Visual.surf(det_a, det_b)\n",
    "                            \n",
    "#                             ssim_scores.append(ssim_score)\n",
    "#                             sift_scores.append(sift_score)\n",
    "#                             surf_scores.append(surf_score)\n",
    "                            \n",
    "#                             avg_ssim = mean(ssim_scores)\n",
    "#                             avg_sift = mean(sift_scores)\n",
    "#                             avg_surf = mean(surf_scores)\n",
    "                            \n",
    "#                             adjusted_ssim = ssim_score/avg_ssim\n",
    "#                             adjusted_sift = sift_score/avg_sift\n",
    "#                             adjusted_surf = surf_score/avg_surf\n",
    "                            \n",
    "#                             adjusted_ssim = ssim_score/ssim_mean\n",
    "#                             adjusted_sift = sift_score/sift_mean\n",
    "#                             adjusted_surf = surf_score/surf_mean\n",
    "                            \n",
    "#                             top_2 = sorted([adjusted_ssim, adjusted_sift, adjusted_surf], reverse=True)[:2]\n",
    "                            \n",
    "#                             # score = (adjusted_ssim+adjusted_sift+adjusted_surf)/3\n",
    "                            \n",
    "#                             score = sum(top_2)/2\n",
    "                            \n",
    "                            distance_score = (search_area-dist)/search_area\n",
    "                            score = (ssim_score*0.7+sift_score*3+surf_score*2.25+distance_score*0.35)/4\n",
    "    \n",
    "                            # print(\"%0.3f, %0.3f, %0.3f, %0.3f\" % (adjusted_ssim, adjusted_sift, adjusted_surf, score))\n",
    "                            # print(\"%0.3f, %0.3f, %0.3f\" % (sift_score, surf_score, score))\n",
    "                            \n",
    "                            if score >= similarity_threshold:                                \n",
    "                                sim_ranking.append((score, det_a, det_b))\n",
    "\n",
    "#             avg_ssim = mean(ssim_scores)\n",
    "#             avg_sift = mean(sift_scores)\n",
    "#             avg_surf = mean(surf_scores)\n",
    "            \n",
    "#             print(avg_ssim, avg_sift, avg_surf)\n",
    "            \n",
    "#             ssim_scores = [avg_ssim]*5\n",
    "#             sift_scores = [avg_sift]*5\n",
    "#             surf_scores = [avg_surf]*5\n",
    "                                \n",
    "            sim_ranking.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "            matched_detections = set([])\n",
    "\n",
    "            for score, det_a, det_b in sim_ranking:\n",
    "                if det_a.index not in matched_detections and det_b.index not in matched_detections:\n",
    "                    track_id = det_a.trajectory                    \n",
    "                    \n",
    "                    det_b.trajectory = track_id\n",
    "                    sequence._tracks[track_id].append(det_b)\n",
    "                    \n",
    "                    matched_detections.add(det_a.index)\n",
    "                    matched_detections.add(det_b.index)\n",
    "                    \n",
    "            unmatched = set(\n",
    "                [det for det in current_frame.detections if det.index not in matched_detections]\n",
    "            )\n",
    "        \n",
    "            for det in unmatched:\n",
    "                det.trajectory = track_counter\n",
    "                sequence._tracks[track_counter] = [det]\n",
    "                track_counter += 1\n",
    "\n",
    "        print(\"%s:%s\" % (current_frame.index, track_counter), end=\" \")\n",
    "        \n",
    "    log.info(\"Finished calculating trajectories.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output(sequence):\n",
    "\n",
    "    # get some nice colors\n",
    "    \n",
    "    colors = []\n",
    "    offset = 50\n",
    "    for i in range(100):\n",
    "        r = randint(0,255)\n",
    "        g = randint(0,255)\n",
    "        b = randint(0,255)\n",
    "\n",
    "        if r < offset or g < offset or b < offset:\n",
    "            colors.append(((r,g,b),(r+offset, g+offset, b+offset)))\n",
    "        else:\n",
    "            colors.append(((r,g,b),(r-offset, g-offset, b-offset)))\n",
    "\n",
    "    # get the frames\n",
    "            \n",
    "    frames = list(sequence._detections.keys())\n",
    "    frames.sort()\n",
    "\n",
    "    video_frames = []\n",
    "\n",
    "    # set output paths\n",
    "    \n",
    "    data_output_path = 'MOT20/train/%s.txt' % \"MOT20-01\"\n",
    "    data_out=open(data_output_path,\"w\")\n",
    "\n",
    "    # process frames, create images and output csv\n",
    "    \n",
    "    for index in frames:\n",
    "        detections = sequence._detections[index]\n",
    "        img = cv2.imread(os.path.join(\"MOT20/train/MOT20-01/img1/%06d.jpg\"%int(index)))\n",
    "        for detection in detections:\n",
    "            if detection.trajectory < 1:\n",
    "                continue\n",
    "\n",
    "            color_index = detection.trajectory % 100\n",
    "            box_color, text_color = colors[color_index]\n",
    "            top_left = (detection.x, detection.y)\n",
    "            bottom_right = (detection.x+detection.w, detection.y+detection.h)\n",
    "            thickness = 2\n",
    "\n",
    "            cv2.rectangle(img, top_left, bottom_right, box_color, thickness)\n",
    "\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            anchor_point = (detection.x, detection.y+20)\n",
    "            scale = 0.75\n",
    "            thickness = 2\n",
    "            line_type = cv2.LINE_AA\n",
    "\n",
    "            cv2.putText(img, str(detection.trajectory), anchor_point, font, scale, text_color, thickness, line_type)\n",
    "\n",
    "            data_out.write(\"%s,%s,%s,%s,%s,%s,%s,%s,%s\\n\"%(\n",
    "                index,\n",
    "                int(detection.trajectory),\n",
    "                int(detection.x),\n",
    "                int(detection.y),\n",
    "                int(detection.w),\n",
    "                int(detection.h),\n",
    "                1,1,\n",
    "                detection.confidence\n",
    "            ))\n",
    "\n",
    "        video_frames.append(img)\n",
    "\n",
    "    # write video out\n",
    "        \n",
    "    video_output_path = 'output/%s.mp4' % \"MOT20-01\"\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'AVC1') # Be sure to use the lower case\n",
    "    fps = 25.0\n",
    "    width = 1920\n",
    "    height = 1080\n",
    "    video_writer = cv2.VideoWriter(video_output_path, fourcc, fps, (width, height))\n",
    "\n",
    "    for video_frame in video_frames:\n",
    "        video_writer.write(video_frame)\n",
    "\n",
    "    video_writer.release()\n",
    "    data_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-05 19:45:38,566 Loading sequence configuration.\n",
      "2020-05-05 19:45:38,570 Loading image info.\n",
      "2020-05-05 19:45:38,575 Loading detections.\n",
      "2020-05-05 19:45:39,658 Calculating trajectories.\n",
      "1:31 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amagill/.envs/three/motaustin/lib/python3.7/site-packages/ipykernel_launcher.py:83: UserWarning: DEPRECATED: skimage.measure.compare_ssim has been moved to skimage.metrics.structural_similarity. It will be removed from skimage.measure in version 0.18.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2:31 3:31 4:31 5:31 6:31 7:31 8:32 9:32 10:32 11:32 12:33 13:33 14:33 15:33 16:35 17:35 18:36 19:36 20:36 21:36 22:36 23:36 24:36 25:36 26:36 27:36 28:36 29:37 30:37 31:37 32:38 33:38 34:38 35:38 36:38 37:38 38:38 39:39 40:40 41:40 42:40 43:40 44:40 45:40 46:40 47:42 48:43 49:43 50:43 51:43 52:43 53:43 54:44 55:44 56:44 57:44 58:44 59:44 60:45 61:45 62:46 63:46 64:46 65:46 66:47 67:47 68:47 69:47 70:47 71:47 72:47 73:47 74:47 75:47 76:47 77:48 78:48 79:51 80:52 81:53 82:55 83:55 84:56 85:56 86:57 87:58 88:59 89:59 90:60 91:62 92:62 93:62 94:62 95:62 96:62 97:62 98:62 99:62 100:62 101:62 102:62 103:62 104:62 105:62 106:62 107:63 108:63 109:63 110:63 111:63 112:64 113:65 114:65 115:65 116:65 117:65 118:69 119:69 120:69 121:70 122:70 123:70 124:71 125:71 126:71 127:71 128:71 129:71 130:71 131:71 132:72 133:73 134:73 135:74 136:74 137:74 138:74 139:74 140:74 141:74 142:74 143:74 144:75 145:75 146:75 147:75 148:75 149:77 150:77 151:77 152:78 153:78 154:79 155:79 156:80 157:80 158:80 159:80 160:81 161:82 162:82 163:82 164:82 165:82 166:83 167:84 168:84 169:84 170:84 171:85 172:85 173:85 174:85 175:87 176:88 177:90 178:92 179:93 180:93 181:93 182:93 183:93 184:94 185:95 186:95 187:96 188:98 189:99 190:99 191:100 192:100 193:100 194:100 195:100 196:100 197:102 198:104 199:105 200:105 201:105 202:105 203:108 204:108 205:109 206:111 207:111 208:112 209:113 210:113 211:115 212:116 213:116 214:117 215:117 216:117 217:118 218:120 219:120 220:120 221:120 222:120 223:121 224:121 225:121 226:121 227:121 228:121 229:121 230:121 231:122 232:123 233:123 234:123 235:125 236:125 237:125 238:125 239:125 240:126 241:126 242:126 243:127 244:127 245:127 246:127 247:127 248:128 249:128 250:128 251:129 252:129 253:129 254:129 255:129 256:129 257:130 258:131 259:131 260:131 261:132 262:132 263:132 264:133 265:133 266:135 267:135 268:136 269:136 270:136 271:136 272:137 273:137 274:138 275:138 276:138 277:138 278:138 279:139 280:139 281:139 282:140 283:141 284:142 285:142 286:142 287:143 288:143 289:143 290:143 291:144 292:144 293:144 294:144 295:144 296:144 297:144 298:145 299:147 300:148 301:149 302:149 303:149 304:149 305:150 306:151 307:151 308:152 309:152 310:152 311:152 312:152 313:152 314:154 315:155 316:158 317:159 318:160 319:160 320:160 321:160 322:160 323:161 324:161 325:162 326:162 327:162 328:163 329:163 330:163 331:164 332:164 333:164 334:164 335:164 336:164 337:164 338:164 339:164 340:164 341:164 342:166 343:167 344:169 345:169 346:169 347:169 348:170 349:171 350:172 351:172 352:173 353:173 354:173 355:173 356:173 357:173 358:173 359:173 360:173 361:173 362:173 363:173 364:173 365:174 366:174 367:174 368:175 369:175 370:176 371:176 372:177 373:177 374:177 375:178 376:178 377:178 378:179 379:179 380:179 381:179 382:179 383:180 384:180 385:180 386:180 387:180 388:180 389:181 390:181 391:181 392:181 393:181 394:182 395:182 396:182 397:182 398:182 399:182 400:182 401:183 402:185 403:185 404:185 405:185 406:185 407:185 408:185 409:185 410:185 411:186 412:186 413:187 414:187 415:187 416:187 417:188 418:188 419:188 420:188 421:188 422:188 423:189 424:189 425:189 426:192 427:192 428:193 429:193 2020-05-05 20:40:09,655 Finished calculating trajectories.\n"
     ]
    }
   ],
   "source": [
    "def main(argv=None):\n",
    "    # arg parse blablabla    \n",
    "    # if args contain config path then set it otherwise use default\n",
    "    sequence_path = SEQUENCE_PATH\n",
    "    config_filename = CONFIG_FILENAME\n",
    "    detections_dir = DETECTIONS_DIR\n",
    "    detections_filename = DETECTIONS_FILENAME\n",
    "    \n",
    "    sequence = Sequence(sequence_path, config_filename, detections_dir, detections_filename)\n",
    "    track(sequence)\n",
    "    \n",
    "    output(sequence)\n",
    "    \n",
    "    return sequence\n",
    "\n",
    "# let's hold on to thi in case we need it for something\n",
    "sequence = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tests(unittest.TestCase):\n",
    "    \n",
    "    def setUp(self):\n",
    "        # load testing config\n",
    "        pass\n",
    "    \n",
    "    def teadDown(self):\n",
    "        # load regular config?\n",
    "        pass\n",
    "    \n",
    "    def test_something_or_other(self):\n",
    "        # let's just make sure we hit all execution paths\n",
    "        pass\n",
    "\n",
    "unittest.main(argv=[''], verbosity=3, exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
