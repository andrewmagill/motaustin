{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import os\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from skimage.measure import compare_ssim\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = \"img1\"\n",
    "gt_path = \"gt/gt.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_list = ['frame','trajectory','x','y','w','h','dco','class','visibility']\n",
    "dtype = {\n",
    "    'frame':int,\n",
    "    'trajectory':int,\n",
    "    'x':int,\n",
    "    'y':int,\n",
    "    'w':int,\n",
    "    'h':int,\n",
    "    'dco':int,\n",
    "    'class':int,\n",
    "    'visibility':float}\n",
    "\n",
    "df = pd.read_csv(gt_path, names=header_list, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "track: 1, length: 150\n",
      "track: 3, length: 150\n",
      "track: 5, length: 150\n",
      "track: 63, length: 150\n",
      "track: 65, length: 150\n",
      "track: 67, length: 150\n",
      "track: 69, length: 150\n",
      "track: 71, length: 150\n",
      "track: 75, length: 150\n",
      "track: 83, length: 150\n",
      "track: 85, length: 150\n",
      "track: 87, length: 150\n",
      "track: 89, length: 150\n",
      "track: 91, length: 150\n",
      "track: 93, length: 150\n",
      "track: 95, length: 150\n",
      "track: 97, length: 150\n",
      "track: 99, length: 150\n"
     ]
    }
   ],
   "source": [
    "target_tracks = range(1,100,2)\n",
    "patch_tracks = {}\n",
    "\n",
    "for track_id in target_tracks:\n",
    "\n",
    "    track_df = df[df['trajectory']==track_id]\n",
    "\n",
    "    if len(track_df) < 150:\n",
    "        continue    \n",
    "\n",
    "    patches = []\n",
    "\n",
    "    for row in track_df.itertuples(index=True, name='Pandas'):\n",
    "\n",
    "        if row.dco == 0:\n",
    "            continue\n",
    "\n",
    "        img_path = os.path.join(img_dir, \"%06d.jpg\" % row.frame)\n",
    "\n",
    "        color_img = cv2.imread(img_path)\n",
    "        gray_img1 = cv2.cvtColor(color_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        start_x, start_y = int(round(row.x)), int(round(row.y))\n",
    "        end_x, end_y = start_x + int(round(row.w)), start_y + int(round(row.h))\n",
    "\n",
    "        crop = gray_img1[start_y:end_y, start_x:end_x]\n",
    "\n",
    "        out_path = os.path.join(\"output/images\",\"track_%s_frame_%s.jpeg\" % (track_id,row.frame))\n",
    "        cv2.imwrite(out_path, crop) \n",
    "\n",
    "        patch = {\n",
    "            \"track_id\": track_id,\n",
    "            \"frame_id\": row.frame,\n",
    "            \"image\": crop,\n",
    "            \"path\": img_path,\n",
    "            \"x\": row.x,\n",
    "            \"y\": row.y,\n",
    "            \"w\": row.x,\n",
    "            \"h\": row.h,\n",
    "            \"vis\": row.visibility\n",
    "        }\n",
    "\n",
    "        patches.append(patch)\n",
    "        if len(patches) >= 150:\n",
    "            break\n",
    "\n",
    "    if len(patches) == 150:\n",
    "        print(\"track: %s, length: %s\"%(track_id, len(patches)))\n",
    "        patch_tracks[track_id] = patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[126, 167, 185, ..., 114, 113, 112],\n",
       "       [124, 168, 189, ..., 105, 104, 103],\n",
       "       [126, 159, 173, ...,  98,  97,  96],\n",
       "       ...,\n",
       "       [ 67,  65,  65, ...,  62,  63,  63],\n",
       "       [ 67,  65,  64, ...,  63,  63,  63],\n",
       "       [ 66,  64,  64, ...,  63,  64,  63]], dtype=uint8)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patch_tracks[95][40]['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sift(a,b):\n",
    "    \n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "    try:\n",
    "        keypoints_1, descriptors_1 = sift.detectAndCompute(a,None)        \n",
    "        keypoints_2, descriptors_2 = sift.detectAndCompute(b,None)\n",
    "    except Exception as ex:\n",
    "        print(str(ex), end=\" \")\n",
    "        return 0 \n",
    "    \n",
    "    # FLANN parameters\n",
    "    FLANN_INDEX_KDTREE = 0\n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "    search_params = dict(checks=50)   # or pass empty dictionary\n",
    "\n",
    "    flann = cv2.FlannBasedMatcher(index_params,search_params)\n",
    "        \n",
    "    try:\n",
    "        matches = flann.knnMatch(descriptors_1,descriptors_2,k=2)\n",
    "    except Exception as ex:\n",
    "        print(str(ex), end=\" \")\n",
    "        return 0\n",
    "\n",
    "    good_matches = []\n",
    "\n",
    "    for i,(m,n) in enumerate(matches):\n",
    "        if m.distance < 0.7*n.distance:\n",
    "            good_matches.append(m)\n",
    "\n",
    "    epsilon = 1e-5\n",
    "\n",
    "    try:\n",
    "        return len(good_matches)/(len(matches)+epsilon)\n",
    "    except Exception as ex:\n",
    "        print(str(ex), end=\" \")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def akaze(a,b):\n",
    "    akaze = cv2.AKAZE_create()\n",
    "\n",
    "    try:\n",
    "        kpts1, desc1 = akaze.detectAndCompute(a, None)\n",
    "        kpts2, desc2 = akaze.detectAndCompute(b, None)\n",
    "    except:\n",
    "        return 0\n",
    "    \n",
    "    matcher = cv2.DescriptorMatcher_create(cv2.DescriptorMatcher_BRUTEFORCE_HAMMING)\n",
    "    \n",
    "    try:\n",
    "        matches = matcher.knnMatch(desc1, desc2, 2)\n",
    "    except:\n",
    "        return 0\n",
    "    \n",
    "    good_matches = []\n",
    "    \n",
    "#     for m, n in matches:\n",
    "#         if m.distance < 0.8 * n.distance:\n",
    "#             good_matches.append(m)\n",
    "    \n",
    "    for i, m_n in enumerate(matches):\n",
    "        if len(m_n) != 2:\n",
    "            continue\n",
    "        m,n = m_n\n",
    "        if m.distance < 0.7*n.distance:\n",
    "            good_matches.append(m)\n",
    "\n",
    "    epsilon = 1e-5\n",
    "\n",
    "    try:\n",
    "        return len(good_matches)/(len(matches)+epsilon)\n",
    "    except Exception as ex:\n",
    "        # print(ex)\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FEATURES = 1000\n",
    "\n",
    "def orb(a,b):\n",
    "    #return 0 # just not working\n",
    "    \n",
    "    # Initiate STAR detector\n",
    "    orb = cv2.ORB_create(nfeatures=100000, scoreType=cv2.ORB_FAST_SCORE)\n",
    "\n",
    "    try:\n",
    "        kp1, des1 = orb.detectAndCompute(a,None)\n",
    "        kp2, des2 = orb.detectAndCompute(b,None)\n",
    "    except Exception as ex:\n",
    "        # print(ex)\n",
    "        return 0\n",
    "\n",
    "    # bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    # matches = bf.match(des1,des2)\n",
    "    # matches = sorted(matches, key = lambda x:x.distance)\n",
    "    FLANN_INDEX_LSH = 6\n",
    "\n",
    "    index_params= dict(algorithm = FLANN_INDEX_LSH,\n",
    "                       table_number = 12, \n",
    "                       key_size = 20,     \n",
    "                       multi_probe_level = 2)\n",
    "\n",
    "    search_params = dict(checks = 50)\n",
    "\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "    try:\n",
    "        matches = flann.knnMatch(des1,des2,k=2)\n",
    "    except Exception as ex:\n",
    "        # print(ex)\n",
    "        return 0\n",
    "    \n",
    "#     if len(matches)>0:\n",
    "#         print(\"%d total matches found\" % len(matches))\n",
    "#     else:\n",
    "#         print(\"No matches were found\")\n",
    "        \n",
    "    \n",
    "    good_matches = []\n",
    "\n",
    "    for i, m_n in enumerate(matches):\n",
    "        if len(m_n) != 2:\n",
    "            continue\n",
    "        m,n = m_n\n",
    "        if m.distance < 0.7*n.distance:\n",
    "            good_matches.append(m)\n",
    "\n",
    "    epsilon = 1e-5\n",
    "\n",
    "    try:\n",
    "        return len(good_matches)/(len(matches)+epsilon)\n",
    "    except Exception as ex:\n",
    "        # print(ex)\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssim(a, b):\n",
    "    (score, diff) = compare_ssim(a, b, full=True)\n",
    "    diff = (diff * 255).astype(\"uint8\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(a, b):\n",
    "    img_a = a['image']\n",
    "    img_b = b['image']\n",
    "    \n",
    "    try:\n",
    "        eq1 = cv2.equalizeHist(img_a)\n",
    "        eq2 = cv2.equalizeHist(img_b)\n",
    "    except:\n",
    "        return (0,0,0)\n",
    "    \n",
    "    dim = (66,180)\n",
    "    try:\n",
    "        eq_scaled_1 = cv2.resize(eq1, dim, interpolation=cv2.INTER_AREA)\n",
    "        eq_scaled_2 = cv2.resize(eq2, dim, interpolation=cv2.INTER_AREA)\n",
    "    except:\n",
    "        return (0,0,0)\n",
    "    \n",
    "    akaze_score = akaze(eq_scaled_1,eq_scaled_2)\n",
    "    sift_score = sift(eq_scaled_1,eq_scaled_2)\n",
    "    # orb_score = orb(eq_scaled_1,eq_scaled_2)\n",
    "    ssim_score = ssim(eq_scaled_1,eq_scaled_2)\n",
    "    \n",
    "    return (akaze_score, sift_score, ssim_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_scores = []\n",
    "right_scores = []\n",
    "across = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bosworth/.envs/three/motaustin/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: DEPRECATED: skimage.measure.compare_ssim has been moved to skimage.metrics.structural_similarity. It will be removed from skimage.measure in version 0.18.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# track: 1, length: 150\n",
    "# track: 3, length: 150\n",
    "# track: 5, length: 150\n",
    "# track: 63, length: 150\n",
    "# track: 65, length: 150\n",
    "# track: 67, length: 150\n",
    "# track: 69, length: 150\n",
    "# track: 71, length: 150\n",
    "# track: 75, length: 150\n",
    "# track: 83, length: 150\n",
    "# track: 85, length: 150\n",
    "# track: 87, length: 150\n",
    "# track: 89, length: 150\n",
    "# track: 91, length: 150\n",
    "# track: 93, length: 150\n",
    "# track: 95, length: 150\n",
    "# track: 97, length: 150\n",
    "# track: 99, length: 150\n",
    "\n",
    "for _ in range(2,14):\n",
    "    keys = list(patch_tracks.keys())\n",
    "    \n",
    "    left = patch_tracks[keys[_]]\n",
    "    right = patch_tracks[keys[_+1]]\n",
    "\n",
    "    for i in range(2,150):\n",
    "\n",
    "        left_previous, left_current = left[i-1], left[i]\n",
    "        right_previous, right_current = right[i-1], right[i]\n",
    "\n",
    "        intra_left = compare(left_previous, left_current)\n",
    "        intra_right = compare(right_previous, right_current)\n",
    "        inter = compare(left_current, right_current)\n",
    "\n",
    "        left_scores.append(intra_left)\n",
    "        right_scores.append(intra_right)\n",
    "        across.append(inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "akaze\n",
      "~~~~~\n",
      "\n",
      "left\tright\tacross\n",
      "\n",
      "\n",
      "1.00\t1.00\t1.00\tmax\n",
      "0.00\t0.00\t0.00\tmin\n",
      "0.56\t0.56\t0.06\tmean\n",
      "\n",
      "1776\n",
      "\n",
      "sift\n",
      "~~~~\n",
      "\n",
      "left\tright\tacross\n",
      "\n",
      "\n",
      "0.77\t0.77\t0.27\tmax\n",
      "0.00\t0.00\t0.00\tmin\n",
      "0.36\t0.37\t0.02\tmean\n",
      "\n",
      "1776\n",
      "\n",
      "ssim\n",
      "~~~~\n",
      "\n",
      "left\tright\tacross\n",
      "\n",
      "\n",
      "0.95\t0.95\t0.34\tmax\n",
      "0.00\t0.00\t0.00\tmin\n",
      "0.70\t0.72\t0.11\tmean\n",
      "\n",
      "1776\n"
     ]
    }
   ],
   "source": [
    "for i,name in [(0,\"akaze\"),(1,\"sift\"),(2,\"ssim\")]:\n",
    "    \n",
    "    print(\"\\n%s\\n%s\\n\\nleft\\tright\\tacross\\n\" % (name,'~'*len(name)))\n",
    "\n",
    "    sift_left = [x[i] for x in left_scores]\n",
    "    sift_right = [x[i] for x in right_scores]\n",
    "    sift_across = [x[i] for x in across]\n",
    "\n",
    "    print(\"\\n%.2f\\t%.2f\\t%.2f\\tmax\"%(max(sift_left), max(sift_right), max(sift_across)))\n",
    "    print(\"%.2f\\t%.2f\\t%.2f\\tmin\"%(min(sift_left), min(sift_right), min(sift_across)))\n",
    "    print(\"%.2f\\t%.2f\\t%.2f\\tmean\\n\"%(statistics.mean(sift_left), statistics.mean(sift_right), statistics.mean(sift_across)))\n",
    "\n",
    "    print(len(sift_across))\n",
    "# for i in range(150):\n",
    "#    print(\"%.2f\\t%.2f\\t%.2f\" % (sift_left[i], sift_right[i], sift_across[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# equalizing histogram\n",
    "\n",
    "# akaze\n",
    "# ~~~~~\n",
    "\n",
    "# left\tright\tacross\n",
    "\n",
    "\n",
    "# 1.00\t1.00\t1.00\tmax\n",
    "# 0.00\t0.00\t0.00\tmin\n",
    "# 0.56\t0.56\t0.06\tmean\n",
    "\n",
    "# 1776\n",
    "\n",
    "# sift\n",
    "# ~~~~\n",
    "\n",
    "# left\tright\tacross\n",
    "\n",
    "\n",
    "# 0.77\t0.77\t0.27\tmax\n",
    "# 0.00\t0.00\t0.00\tmin\n",
    "# 0.36\t0.37\t0.02\tmean\n",
    "\n",
    "# 1776\n",
    "\n",
    "# ssim\n",
    "# ~~~~\n",
    "\n",
    "# left\tright\tacross\n",
    "\n",
    "\n",
    "# 0.95\t0.95\t0.34\tmax\n",
    "# 0.00\t0.00\t0.00\tmin\n",
    "# 0.70\t0.72\t0.11\tmean\n",
    "\n",
    "# 1776\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# akaze\n",
    "# ~~~~~\n",
    "\n",
    "# left\tright\tacross\n",
    "\n",
    "\n",
    "# 1.00\t1.00\t1.00\tmax\n",
    "# 0.00\t0.00\t0.00\tmin\n",
    "# 0.23\t0.23\t0.01\tmean\n",
    "\n",
    "# 1776\n",
    "\n",
    "# sift\n",
    "# ~~~~\n",
    "\n",
    "# left\tright\tacross\n",
    "\n",
    "\n",
    "# 1.00\t1.00\t0.54\tmax\n",
    "# 0.00\t0.00\t0.00\tmin\n",
    "# 0.59\t0.58\t0.04\tmean\n",
    "\n",
    "# 1776\n",
    "\n",
    "# ssim\n",
    "# ~~~~\n",
    "\n",
    "# left\tright\tacross\n",
    "\n",
    "\n",
    "# 0.98\t0.98\t0.74\tmax\n",
    "# 0.00\t0.00\t0.00\tmin\n",
    "# 0.87\t0.87\t0.37\tmean\n",
    "\n",
    "# 1776\n",
    "\n",
    "# scaling all images to (66,180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sift (goodness threshold = 0.6)\n",
    "\n",
    "# left\tright\tacross\n",
    "\n",
    "\n",
    "# 1.00\t1.00\t0.62\tmax\n",
    "# 0.00\t0.00\t0.00\tmin\n",
    "# 0.54\t0.53\t0.02\tmean\n",
    "\n",
    "# 1628\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sift (0.65 goodness threshold)\n",
    "\n",
    "# left\tright\tacross\n",
    "\n",
    "\n",
    "# 1.00\t1.00\t0.62\tmax\n",
    "# 0.00\t0.17\t0.00\tmin\n",
    "# 0.55\t0.56\t0.03\tmean\n",
    "\n",
    "# 1776"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sift (0.75 goodness score)\n",
    "\n",
    "# left\tright\tacross\n",
    "\n",
    "\n",
    "# 1.00\t1.00\t0.64\tmax\n",
    "# 0.00\t0.00\t0.00\tmin\n",
    "# 0.59\t0.58\t0.06\tmean\n",
    "\n",
    "# 1776"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sift (0.8 goodness threshold)\n",
    "\n",
    "# left\tright\tacross\n",
    "\n",
    "\n",
    "# 1.00\t1.00\t0.78\tmax\n",
    "# 0.00\t0.00\t0.00\tmin\n",
    "# 0.62\t0.61\t0.10\tmean\n",
    "\n",
    "# 1776"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
