{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configparser import ConfigParser\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## constants\n",
    "############\n",
    "\n",
    "CONFIG_PATH = './conf/config.ini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## config\n",
    "#########\n",
    "\n",
    "config = ConfigParser()\n",
    "\n",
    "config.read(CONFIG_PATH)\n",
    "sequence_config = dict(config['Sequence'])\n",
    "tracking_config = dict(config['Tracking'])\n",
    "\n",
    "sequence_config['frame_rate'] = config.getint(\"Sequence\",\"frame_rate\")\n",
    "sequence_config['seq_length'] = config.getint(\"Sequence\",\"seq_length\")\n",
    "sequence_config['img_width'] = config.getint(\"Sequence\",\"img_width\")\n",
    "sequence_config['img_height'] = config.getint(\"Sequence\",\"img_height\")\n",
    "\n",
    "tracking_config['scaled_height'] = config.getint(\"Tracking\",\"scaled_height\")\n",
    "tracking_config['scaled_width'] = config.getint(\"Tracking\",\"scaled_width\")\n",
    "tracking_config['memory'] = config.getint(\"Tracking\",\"memory\")\n",
    "tracking_config['similarity_threshold'] = config.getfloat(\"Tracking\",\"similarity_threshold\")\n",
    "tracking_config['confidence_threshold'] = config.getfloat(\"Tracking\",\"confidence_threshold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## input\n",
    "########\n",
    "\n",
    "# pos       name                    description\n",
    "# 1      frame number           frame in which the object is present\n",
    "# 2      identity number        trajectory id (-1 default for no track)\n",
    "# 3      bounding box x         x value from top left of bounding box\n",
    "# 4      bounding box y         y value from top left of bounding box\n",
    "# 5      bounding box width     width of bounding box in pixels\n",
    "# 6      bounding box height    height of bounding box in pixels\n",
    "# 7      confidence score      class detection confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## output\n",
    "#########\n",
    "\n",
    "# pos       name                    description\n",
    "# 1      frame number           frame in which the object is present\n",
    "# 2      identity number        trajectory id (-1 default for no track)\n",
    "# 3      bounding box x         x value from top left of bounding box\n",
    "# 4      bounding box y         y value from top left of bounding box\n",
    "# 5      bounding box width     width of bounding box in pixels\n",
    "# 6      bounding box height    height of bounding box in pixels\n",
    "# 7      confidence score*      class detection confidence (gt: 1 or 0)\n",
    "# 8      class*                 type of class (1 for pedestrian)\n",
    "# 9      visibility*            percent visible (percent occluded = 1-visibility)\n",
    "\n",
    "#        *no need to output these values, will be ignore by evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Point(object):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Distance(object):\n",
    "    \n",
    "    @staticmethod\n",
    "    def l2_norm(obj1, obj2):\n",
    "        p1, p2 = None, None\n",
    "        \n",
    "        if type(obj1) == Box:\n",
    "            p1 = obj1.centroid\n",
    "        elif type(obj1) == Point:\n",
    "            p1 = obj1\n",
    "        \n",
    "        if type(obj1) == Box:\n",
    "            p2 = obj2.centroid\n",
    "        elif type(obj1) == Point:\n",
    "            p2 = obj2\n",
    "        \n",
    "        return math.sqrt((p2.x-p1.x)**2 + (p2.y-p1.y)**2)\n",
    "    \n",
    "    @staticmethod\n",
    "    def jaccard(obj1, obj2):\n",
    "        \n",
    "        if type(obj1) == Box and type(obj2) == Box:\n",
    "            \n",
    "            # just to make this a little more intuitive\n",
    "            box1, box2 = obj1, obj2\n",
    "            \n",
    "            # to make this easier we'll create two arrays, [x1, y1, x2, y2], s.t.\n",
    "            # (x1, y1) is the top left point for a box and (x2, y2) is the bottom right\n",
    "            a = [box1.x, box1.y, box1.x + box1.w, box1.y + box1.h]\n",
    "            b = [box2.x, box2.y, box2.x + box2.w, box2.y + box2.h]\n",
    "            \n",
    "            # intersection\n",
    "            \n",
    "            # find the boundary of the intersection between the two boxes\n",
    "            x1 = max(a[0], b[0]) # rightmost x of the top left points\n",
    "            y1 = max(a[1], b[1]) # lowest y of the top left points\n",
    "            x2 = min(a[2], b[2]) # leftmost x of the bottom right points\n",
    "            y2 = min(a[3], b[3]) # highest y of the bottom right points\n",
    "            \n",
    "            # find the area of the intersection\n",
    "            width = (x2 - x1)\n",
    "            height = (y2 - y1)\n",
    "            \n",
    "            # if no overlap don't bother going further, return 0\n",
    "            if width <= 0 or height <= 0:\n",
    "                return 0\n",
    "            \n",
    "            area_of_intersection = width * height\n",
    "            \n",
    "            # area of union\n",
    "            \n",
    "            # this is easy, you don't need to know where the boxes are, since you've\n",
    "            # already calculated the intersection. if you just add the total area\n",
    "            # of box_a and the the area of box_b you've counted the intersection\n",
    "            # twice, so just subtract the intersection once and you have the answer\n",
    "            a_area = (a[2] - a[0]) * (a[3] - a[1])\n",
    "            b_area = (b[2] - b[0]) * (b[3] - b[1])\n",
    "            \n",
    "            area_of_union = a_area + b_area - area_of_intersection\n",
    "            \n",
    "            # protect again division by zero\n",
    "            epsilon = 1e-5\n",
    "            \n",
    "            iou = area_of_intersection / (area_of_union + epsilon)\n",
    "            return iou\n",
    "    \n",
    "        elif type(obj1) == numpy.ndarray and type(obj2) == numpy.ndarray:\n",
    "            descriptors1, descriptors2 = obj1, obj2\n",
    "            \n",
    "            # brute force feature matching using manhattan distance\n",
    "        \n",
    "            bf = cv2.BFMatcher(cv2.NORM_L1, crossCheck=True)\n",
    "\n",
    "            matches = bf.match(descriptors_1, descriptors_2)\n",
    "            matches = sorted(matches, key = lambda x:x.distance)\n",
    "\n",
    "            # TODO do we want to cutoff at a threshold?\n",
    "            \n",
    "            intersection = len(matches)\n",
    "            union = len(descriptors1)+len(descriptors2)-intersection\n",
    "\n",
    "            epsilon = 1e-5\n",
    "            \n",
    "            return intersection / (union+epsilon)\n",
    "    \n",
    "    @staticmethod\n",
    "    # def sift(box1, box2, frame_a_id, frame_b_id, img_path=sequence_config['img_path'], new_w=tracking_config['scaled_width'], new_h=tracking_config['scaled_height']):\n",
    "    def sift(box1, box2):    \n",
    "        \n",
    "        img_path = sequence_config['img_path']\n",
    "        \n",
    "        # get filepaths\n",
    "        \n",
    "        img1_path = os.path.join(img_path, \"%06d.jpg\" % box1.frame)\n",
    "        img2_path = os.path.join(img_path, \"%06d.jpg\" % box2.frame)\n",
    "        \n",
    "        print(img1_path, img2_path)\n",
    "        \n",
    "        # read image files as grayscale\n",
    "        \n",
    "        img1 = cv2.imread(img1_path, 0)\n",
    "        img2 = cv2.imread(img2_path, 0)\n",
    "        \n",
    "#         # gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "#         # gray2 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # cut out the firt object from the first image\n",
    "        \n",
    "        p1, p2 = box1.coords\n",
    "        start_x, start_y = int(round(p1.x)), int(round(p1.y))\n",
    "        end_x, end_y = int(round(p2.x)),int(round(p2.y))\n",
    "        \n",
    "        crop1 = img1[start_y:end_y, start_x:end_x]\n",
    "        \n",
    "        # cut out the second object from the second image\n",
    "        \n",
    "        p1, p2 = box2.coords\n",
    "        start_x, start_y = int(round(p1.x)), int(round(p1.y))\n",
    "        end_x, end_y = int(round(p2.x)),int(round(p2.y))\n",
    "        \n",
    "        crop2 = img2[start_y:end_y, start_x:end_x]\n",
    "        \n",
    "        cv2.imshow(\"img1\", crop1)\n",
    "        cv2.imshow(\"img2\", crop2)\n",
    "          \n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "#         # calculate the amount to scale in both directions\n",
    "        \n",
    "#         img_1_x_scale = new_w/box1.w\n",
    "#         img_1_y_scale = new_h/box1.h\n",
    "        \n",
    "#         img_1_x_scale = new_w/box2.w\n",
    "#         img_1_y_scale = new_h/box2.h\n",
    "        \n",
    "#         # resize both cropped images\n",
    "        \n",
    "#         scaled_img1 = cv2.resize(img1, None, fx=img_1_x_scale, fy=img_1_y_scale, interpolation = cv2.INTER_CUBIC)\n",
    "#         scaled_img2 = cv2.resize(img2, None, fx=img_2_x_scale, fy=img_2_y_scale, interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "#         # TODO do I even need to scale? SIFT is Scale Invariant\n",
    "\n",
    "#         scaled_img1 = cv2.resize(img1, (new_w, new_h), interpolation = cv2.INTER_CUBIC)\n",
    "#         scaled_img2 = cv2.resize(img2, (new_w, new_h), interpolation = cv2.INTER_CUBIC)\n",
    "        \n",
    "#         cv2.imshow(\"img1\", scaled_img1)\n",
    "#         cv2.imshow(\"img2\", scaled_img2)\n",
    "        \n",
    "#         cv2.waitKey(0)\n",
    "#         cv2.destroyAllWindows()\n",
    "        \n",
    "        # find keypoints and descriptors\n",
    "        \n",
    "        # https://docs.opencv.org/4.3.0/da/df5/tutorial_py_sift_intro.html\n",
    "        \n",
    "        print(\"DEBUG 1\")\n",
    "        \n",
    "        sift = cv2.xfeatures2d.SIFT_create()\n",
    "        \n",
    "        print(\"DEBUG 2\")\n",
    "        \n",
    "        keypoints_1, descriptors_1 = sift.detectAndCompute(scaled_img1,None)\n",
    "        \n",
    "        print(\"DEBUG 3\")\n",
    "        \n",
    "        keypoints_2, descriptors_2 = sift.detectAndCompute(scaled_img2,None)\n",
    "\n",
    "        print(\"DEBUG 4\")\n",
    "        \n",
    "        # brute force feature matching using manhattan distance\n",
    "        \n",
    "        bf = cv2.BFMatcher(cv2.NORM_L1, crossCheck=True)\n",
    "\n",
    "        print(\"DEBUG 5\")\n",
    "        \n",
    "        matches = bf.match(descriptors_1,descriptors_2)\n",
    "        \n",
    "        print(\"DEBUG 6\")\n",
    "        \n",
    "        matches = sorted(matches, key = lambda x:x.distance)\n",
    "        \n",
    "        # TODO do we want to cutoff at a threshold?\n",
    "        \n",
    "        pprint(matches)\n",
    "        pprint(keypoints1)\n",
    "        pprint(keypoints2)\n",
    "        \n",
    "        return len(matches) / (len(descriptors_1)+len(descriptors_2))\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Box(object):\n",
    "    def __init__(self, x, y, w, h, index=None, frame=None, track_id=None, conf=None):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.w = w\n",
    "        self.h = h\n",
    "        self.index = index\n",
    "        self.frame = frame\n",
    "        self.track_id = track_id\n",
    "        self.conf = conf\n",
    "    \n",
    "    @property\n",
    "    def coords(self):\n",
    "        return(Point(self.x, self.y), Point(self.x+self.w, self.y+self.h))\n",
    "    \n",
    "    @property\n",
    "    def centroid(self):\n",
    "        return Point(self.x+(self.w*0.5), self.y+(self.h*0.5))\n",
    "\n",
    "    def copy(self, offset_x=0, offset_y=0):\n",
    "        return Box(\n",
    "            self.x + offset_x, \n",
    "            self.y + offset_y, \n",
    "            self.w, self.h, \n",
    "            self.index, self.frame,\n",
    "            self.track_id, self.conf\n",
    "        )\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"Box(%s, %s, %s, %s, %s, %s, %s, %s)\" % (\n",
    "            self.x, self.y, self.w, self.h, self.index, self.frame, self.track_id, self.conf\n",
    "        )\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"index: %s, frame: %s, track: %s, x: %s, y: %s, w: %s, h: %s, conf: %s\" % (\n",
    "            self.index, self.frame, self.track_id, self.x, self.y, self.w, self.h, self.conf\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Track(object):\n",
    "    counter = 1\n",
    "    \n",
    "    def __init__(self, o):\n",
    "        self.id = Track.counter\n",
    "        Track.counter += 1\n",
    "        \n",
    "        if type(o) == list:\n",
    "            boxes = o\n",
    "            self.boxes = boxes\n",
    "        elif type(o) == Box:\n",
    "            box = o\n",
    "            self.boxes = [box]\n",
    "            \n",
    "        self.is_active = True\n",
    "    \n",
    "    def add(self, box):\n",
    "        box.track_id = self.id\n",
    "        self.boxes.append(box)\n",
    "    \n",
    "    @staticmethod\n",
    "    def angle(box1, box2):\n",
    "        \n",
    "        p1 = box1.centroid\n",
    "        p2 = box2.centroid\n",
    "\n",
    "        rads = math.atan2(p1.y-p2.y, p1.x-p2.x)\n",
    "        # deg = math.degrees(rads)\n",
    "        # return rads\n",
    "        return rads\n",
    "    \n",
    "    @staticmethod\n",
    "    def distance(box1, box2):\n",
    "            \n",
    "        p1 = box1.centroid\n",
    "        p2 = box2.centroid\n",
    "\n",
    "        distance = math.hypot((p2.x-p1.x),(p2.y-p1.y))\n",
    "        # distance = sqrt((x2-x1)**2 + (y2-y1)**2)\n",
    "        \n",
    "        return distance\n",
    "    \n",
    "    def predict(self, frame_id):\n",
    "        end_of_track = self.boxes[-1] # this is the last box added to the track\n",
    "        \n",
    "        frames_since_last_match = frame_id - end_of_track.frame\n",
    "        \n",
    "        if frames_since_last_match > tracking_config['memory']:\n",
    "            # forget this track if it's outside the memory window\n",
    "            return None\n",
    "        \n",
    "        if len(self.boxes)==1:\n",
    "            predicted_location = end_of_track.copy()\n",
    "        else:\n",
    "            second_to_end = self.boxes[-2]\n",
    "            \n",
    "            angle = Track.angle(second_to_end, end_of_track)\n",
    "            distance = Track.distance(second_to_end, end_of_track)\n",
    "            \n",
    "            # this is a little expirement, continue the movement through occluded fraes\n",
    "            # distance = distance * frames_since_last_match # i don't think it panned out\n",
    "            \n",
    "            offset_x = distance*math.sin(angle)\n",
    "            offset_y = distance*math.cos(angle)\n",
    "            \n",
    "            # predicted_location = current.copy() # match last location\n",
    "            predicted_location = end_of_track.copy(offset_x, offset_y) # estimate trajectory\n",
    "            \n",
    "        # predicted_location.frame += 1\n",
    "\n",
    "        return predicted_location\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"Track([<__main__.Box>]) count: %s\" % len(self.boxes)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"TrackID: %s, Frames: %s-%s\" % (\n",
    "            self.id, self.boxes[0].frame, self.boxes[-1].frame\n",
    "        )\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Frame(object):\n",
    "    def __init__(self, number, boxes=None):\n",
    "        self.id = number\n",
    "        \n",
    "        if boxes is None:\n",
    "            boxes = []\n",
    "        \n",
    "        self._boxes = boxes\n",
    "    \n",
    "    def add(self, box):\n",
    "        if type(box) == Box:\n",
    "            self._boxes.append(box)\n",
    "        elif type(box) == list:\n",
    "            self._boxes.extend(boxes)\n",
    "    \n",
    "    @property\n",
    "    def objects(self):\n",
    "        return self._boxes\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"Frame(%s, [<__main__.Box>]) count: %s\" % (self.id, len(self.boxes))\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"FrameID: %s, Count: %s\" % (self.id, len(self.boxes))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Detections(object):\n",
    "    def __init__(self, data_path=tracking_config['detections_path']):\n",
    "        self.data_path = data_path\n",
    "        self.mean_width = None\n",
    "        self.mean_height = None\n",
    "        self._df = None\n",
    "        self._frames = {}\n",
    "        self.start_index = None\n",
    "        self.end_index = None\n",
    "        self.count = sequence_config['seq_length']\n",
    "        self._pos = None\n",
    "        self._load()\n",
    "    \n",
    "    def _load(self, conf_threshold=tracking_config['confidence_threshold']):\n",
    "        \n",
    "        header_list = ['frame','trajectory','x','y','w','h','confidence']\n",
    "        dtype = {'frame':int,'trajectory':int,'x':float,'y':float,'w':float,'h':float,'confidence':float}\n",
    "        \n",
    "        df = pd.read_csv(self.data_path, names=header_list, dtype=dtype)\n",
    "\n",
    "        # filter out low confidence detections\n",
    "        \n",
    "        self._df = df[df[\"confidence\"] >= conf_threshold]\n",
    "        \n",
    "        self.mean_width = self._df[\"w\"].mean()\n",
    "        self.mean_height = self._df[\"h\"].mean()\n",
    "\n",
    "        # get the indices for the first and last frames\n",
    "\n",
    "        self.start_index = self._df['frame'].min()\n",
    "        self.end_index = self._df['frame'].max() + 1\n",
    "\n",
    "        for i in range(self.start_index, self.end_index):\n",
    "            self._frames[i] = self._df.loc[df['frame']==i,:]\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        return self.next()\n",
    "    \n",
    "    def next(self):\n",
    "        while True:\n",
    "            if self._pos is None:\n",
    "                self._pos = self.start_index        \n",
    "            elif self._pos < self.end_index:\n",
    "                current, self._pos = self._pos, self._pos + 1\n",
    "                current_frame = self._frames[current]\n",
    "\n",
    "                detection_boxes = []\n",
    "\n",
    "                for i, detection in current_frame.iterrows():                \n",
    "                    frame_no, traj_no, x, y, w, h, conf = detection\n",
    "                    box = Box(x, y, w, h, int(i), int(frame_no), -1, conf)\n",
    "                    detection_boxes.append(box)\n",
    "\n",
    "                return Frame(current, detection_boxes)\n",
    "            else:\n",
    "                # self._pos = None\n",
    "                raise StopIteration()\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \"Detections(%s, %s, %s, %s, %s, %s)\" % (\n",
    "            self.data_path, self.mean_width, self.mean_height, \n",
    "            self.start_index, self.end_index, self.count\n",
    "        )\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"path: %s, name: %s, mean_width: %s, mean_height: %s, start_index: %s, end_index: %s, count: %s)\" % (\n",
    "            self.data_path, sequence_config['name'], \n",
    "            self.mean_width, self.mean_height, \n",
    "            self.start_index, self.end_index, self.count\n",
    "        )\n",
    "    \n",
    "    def __len__(self):\n",
    "        # TODO this is really the length of the frames, that's how\n",
    "        # I use it in trajectories... should rethink this\n",
    "        return self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trajectories(object):\n",
    "    def __init__(self):\n",
    "        # reset track counter\n",
    "        Track.counter = 1\n",
    "        self._tracks = {}\n",
    "        self.detections = Detections()\n",
    "    \n",
    "    def add(self, o):\n",
    "        if type(o) == Box:\n",
    "            box = o\n",
    "            track = Track(box)\n",
    "            box.track_id = track.id\n",
    "            self._tracks[track.id] = track\n",
    "        if type(o) == Track:\n",
    "            track = o\n",
    "            self._tracks[track.id] = track\n",
    "    \n",
    "    def _matching(self, predictions, current_frame):\n",
    "        measure = tracking_config['distance_measure']\n",
    "        \n",
    "        if measure == 'euclidean':\n",
    "            distance_func = Distance.l2_norm\n",
    "        elif measure == 'iou':\n",
    "            distance_func = Distance.jaccard\n",
    "        else:\n",
    "            distance_func = Distance.sift\n",
    "    \n",
    "        sim_vector = []\n",
    "        computed = []\n",
    "        \n",
    "        for box_a in predictions:\n",
    "            for box_b in current_frame.objects:\n",
    "                \n",
    "                if box_a.index is None or box_b.index is None:\n",
    "                    raise Exception(\"Boundary index may not be None.\")                    \n",
    "                    \n",
    "                this_pair = set([box_a.index, box_b.index])\n",
    "                \n",
    "                if True: # this_pair not in computed:\n",
    "                    \n",
    "                    similarity = distance_func(box_a, box_b)\n",
    "                    \n",
    "                    if measure == 'euclidean':\n",
    "                        if similarity <= tracking_config['similarity_threshold']:\n",
    "                            sim_vector.append((similarity, box_a, box_b))\n",
    "                    else:\n",
    "                        if similarity >= tracking_config['similarity_threshold']:\n",
    "                            sim_vector.append((similarity, box_a, box_b))\n",
    "                        \n",
    "                    computed.append(this_pair)\n",
    "\n",
    "        if measure == 'euclidean':            \n",
    "            sim_vector.sort(key=lambda x: x[0])\n",
    "        else:\n",
    "            sim_vector.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # print([x[0] for x in sim_vector[::3]], end=\", \")\n",
    "            \n",
    "        matching_pairs = []\n",
    "        matched_objects = set([])\n",
    "\n",
    "        for distance, box_1, box_2 in sim_vector:\n",
    "            \n",
    "            # we want to ensure that we only return the top matches, so we keep track\n",
    "            # of the objects already matched and ignore less similar matches for these objects\n",
    "            \n",
    "            if box_1.index not in matched_objects and box_2.index not in matched_objects:                \n",
    "            \n",
    "                match = (box_1, box_2)\n",
    "                matching_pairs.append(match)\n",
    "                \n",
    "                matched_objects.add(box_1.index)\n",
    "                matched_objects.add(box_2.index)\n",
    "        \n",
    "        # unmatched detections in current frame need to become new tracks\n",
    "        \n",
    "        unmatched = set(\n",
    "            [box for box in current_frame.objects if box.index not in matched_objects]\n",
    "        )\n",
    "        \n",
    "        for box in unmatched:\n",
    "            self.add(box)\n",
    "        \n",
    "        print(len(self._tracks), end =\" \")\n",
    "        \n",
    "        return matching_pairs\n",
    "    \n",
    "    def calculate(self, start=0, end=None):\n",
    "        if end is None:\n",
    "            end = len(self.detections)\n",
    "            \n",
    "        # for frame in self.detections[start:end]: # Detections not subscriptable\n",
    "        \n",
    "        for frame in self.detections:\n",
    "            # TODO fix this mess with dataframes\n",
    "            df = self.detections._frames[frame.id]\n",
    "            \n",
    "            if len(self._tracks)==0:\n",
    "                for box in frame.objects:\n",
    "                    self.add(box)\n",
    "                    \n",
    "                    # TODO fix this mess with dataframes\n",
    "                    df.loc[box.index, \"trajectory\"] = box.track_id\n",
    "                continue\n",
    "\n",
    "            predictions = []\n",
    "            for track_id, track in self._tracks.items():\n",
    "                prediction = track.predict(frame.id)\n",
    "                if prediction is not None:\n",
    "                    predictions.append(prediction)\n",
    "\n",
    "            matching_pairs = self._matching(predictions, frame)\n",
    "            for box_1, box_2 in matching_pairs:\n",
    "                track = self._tracks[box_1.track_id]\n",
    "                track.add(box_2)\n",
    "                \n",
    "                # TODO fix this mess with dataframes\n",
    "                df.loc[box_2.index, \"trajectory\"] = box_1.track_id\n",
    "\n",
    "    def output(self, path=None):\n",
    "        if path is None:            \n",
    "            for track_id, boxes in self._tracks.items():\n",
    "                print(track_id, boxes)\n",
    "        else:\n",
    "            # write\n",
    "            pass\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bosworth/anaconda3/envs/motaustin-env/lib/python3.6/site-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 26 27 27 27 27 27 27 27 27 27 27 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 30 30 30 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 32 33 33 34 34 34 34 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 37 37 37 37 37 37 37 37 37 37 37 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 39 39 39 39 39 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 42 42 42 42 42 42 42 42 42 42 43 43 43 43 43 43 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 49 49 49 49 49 49 49 49 49 49 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 51 51 52 52 52 52 52 52 52 53 53 53 53 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 55 55 55 55 55 55 55 56 56 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 1 TrackID: 1, Frames: 1-576\n",
      "2 TrackID: 2, Frames: 1-594\n",
      "3 TrackID: 3, Frames: 1-1050\n",
      "4 TrackID: 4, Frames: 1-1050\n",
      "5 TrackID: 5, Frames: 1-599\n",
      "6 TrackID: 6, Frames: 1-1050\n",
      "7 TrackID: 7, Frames: 1-425\n",
      "8 TrackID: 8, Frames: 1-66\n",
      "9 TrackID: 9, Frames: 1-720\n",
      "10 TrackID: 10, Frames: 1-1050\n",
      "11 TrackID: 11, Frames: 1-1050\n",
      "12 TrackID: 12, Frames: 1-244\n",
      "13 TrackID: 13, Frames: 1-1050\n",
      "14 TrackID: 14, Frames: 1-1050\n",
      "15 TrackID: 15, Frames: 1-1050\n",
      "16 TrackID: 16, Frames: 1-15\n",
      "17 TrackID: 17, Frames: 1-964\n",
      "18 TrackID: 18, Frames: 1-1050\n",
      "19 TrackID: 19, Frames: 1-217\n",
      "20 TrackID: 20, Frames: 1-636\n",
      "21 TrackID: 21, Frames: 1-1032\n",
      "22 TrackID: 22, Frames: 1-1050\n",
      "23 TrackID: 23, Frames: 1-522\n",
      "24 TrackID: 24, Frames: 1-18\n",
      "25 TrackID: 25, Frames: 1-1050\n",
      "26 TrackID: 26, Frames: 1-6\n",
      "27 TrackID: 27, Frames: 4-455\n",
      "28 TrackID: 28, Frames: 14-1050\n",
      "29 TrackID: 29, Frames: 38-1050\n",
      "30 TrackID: 30, Frames: 38-560\n",
      "31 TrackID: 31, Frames: 41-1050\n",
      "32 TrackID: 32, Frames: 58-61\n",
      "33 TrackID: 33, Frames: 59-1050\n",
      "34 TrackID: 34, Frames: 61-109\n",
      "35 TrackID: 35, Frames: 65-1050\n",
      "36 TrackID: 36, Frames: 98-1050\n",
      "37 TrackID: 37, Frames: 161-1042\n",
      "38 TrackID: 38, Frames: 172-334\n",
      "39 TrackID: 39, Frames: 214-1050\n",
      "40 TrackID: 40, Frames: 219-602\n",
      "41 TrackID: 41, Frames: 259-556\n",
      "42 TrackID: 42, Frames: 306-363\n",
      "43 TrackID: 43, Frames: 316-572\n",
      "44 TrackID: 44, Frames: 322-1050\n",
      "45 TrackID: 45, Frames: 343-1050\n",
      "46 TrackID: 46, Frames: 437-996\n",
      "47 TrackID: 47, Frames: 467-546\n",
      "48 TrackID: 48, Frames: 538-1050\n",
      "49 TrackID: 49, Frames: 637-1050\n",
      "50 TrackID: 50, Frames: 647-1050\n",
      "51 TrackID: 51, Frames: 875-1050\n",
      "52 TrackID: 52, Frames: 877-997\n",
      "53 TrackID: 53, Frames: 884-1050\n",
      "54 TrackID: 54, Frames: 888-1050\n",
      "55 TrackID: 55, Frames: 954-1050\n",
      "56 TrackID: 56, Frames: 961-1050\n",
      "57 TrackID: 57, Frames: 963-1016\n"
     ]
    }
   ],
   "source": [
    "trajectories = Trajectories()\n",
    "trajectories.calculate()\n",
    "trajectories.output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "colors = []\n",
    "offset = 50\n",
    "for i in range(100):\n",
    "    r = randint(0,255)\n",
    "    g = randint(0,255)\n",
    "    b = randint(0,255)\n",
    "    \n",
    "    if r < offset or g < offset or b < offset:\n",
    "        colors.append(((r,g,b),(r+offset, g+offset, b+offset)))\n",
    "    else:\n",
    "        colors.append(((r,g,b),(r-offset, g-offset, b-offset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_frames = []\n",
    "img_path = \"img1\"\n",
    "\n",
    "img_filenames = [f for f in os.listdir(img_path) if os.path.isfile(os.path.join(img_path, f))]\n",
    "img_filenames.sort()\n",
    "\n",
    "for img_filename in img_filenames:\n",
    "    frame_id = int(img_filename.split('.')[0])\n",
    "    frame = trajectories.detections._frames[frame_id]\n",
    "    img = cv2.imread(os.path.join(img_path, img_filename))\n",
    "    for index, (frame,track,x,y,w,h,conf) in frame.iterrows():\n",
    "        \n",
    "        track, x, y, w, h = int(track), int(x), int(y), int(w), int(h)\n",
    "        if track < 1:\n",
    "            continue\n",
    "        \n",
    "        color_index = track % 100\n",
    "        box_color, text_color = colors[color_index]\n",
    "        \n",
    "        top_left = (x, y)\n",
    "        bottom_right = (x+w, y+h)\n",
    "        thickness = 2\n",
    "        \n",
    "        cv2.rectangle(img, top_left, bottom_right, box_color, thickness)\n",
    "        \n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        anchor_point = (x, y+20)\n",
    "        scale = 0.75\n",
    "        thickness = 2\n",
    "        line_type = cv2.LINE_AA\n",
    "        \n",
    "        cv2.putText(img, str(track), anchor_point, font, scale, text_color, thickness, line_type)\n",
    "        \n",
    "    video_frames.append(img)\n",
    "\n",
    "output_path = 'output/%s.mp4' % tracking_config['out_seq_name']\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "fps = 30.0\n",
    "width = 1920\n",
    "height = 1080\n",
    "video_writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "for video_frame in video_frames:\n",
    "    video_writer.write(video_frame)\n",
    "\n",
    "video_writer.release()\n",
    "video_frames.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
