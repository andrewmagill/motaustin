{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configparser import ConfigParser\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## constants\n",
    "############\n",
    "\n",
    "CONFIG_PATH = './conf/config.ini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## config\n",
    "#########\n",
    "\n",
    "config = ConfigParser()\n",
    "\n",
    "config.read(CONFIG_PATH)\n",
    "sequence_config = dict(config['Sequence'])\n",
    "tracking_config = dict(config['Tracking'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## input\n",
    "########\n",
    "\n",
    "# pos       name                    description\n",
    "# 1      frame number           frame in which the object is present\n",
    "# 2      identity number        trajectory id (-1 default for no track)\n",
    "# 3      bounding box x         x value from top left of bounding box\n",
    "# 4      bounding box y         y value from top left of bounding box\n",
    "# 5      bounding box width     width of bounding box in pixels\n",
    "# 6      bounding box height    height of bounding box in pixels\n",
    "# 7      confidence score      class detection confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## output\n",
    "#########\n",
    "\n",
    "# pos       name                    description\n",
    "# 1      frame number           frame in which the object is present\n",
    "# 2      identity number        trajectory id (-1 default for no track)\n",
    "# 3      bounding box x         x value from top left of bounding box\n",
    "# 4      bounding box y         y value from top left of bounding box\n",
    "# 5      bounding box width     width of bounding box in pixels\n",
    "# 6      bounding box height    height of bounding box in pixels\n",
    "# 7      confidence score*      class detection confidence (gt: 1 or 0)\n",
    "# 8      class*                 type of class (1 for pedestrian)\n",
    "# 9      visibility*            percent visible (percent occluded = 1-visibility)\n",
    "\n",
    "#        *no need to output these values, will be ignore by evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Point(object):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Keypoints(object):\n",
    "    def __init__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Distance(object):\n",
    "    \n",
    "    @staticmathod\n",
    "    def norm_l2(obj1, obj2):\n",
    "        p1, p2 = None, None\n",
    "        \n",
    "        if type(obj1) == Box:\n",
    "            p1 = obj1.centroid\n",
    "        elif type(obj1) == Point:\n",
    "            p1 = obj1\n",
    "        \n",
    "        if type(obj1) == Box:\n",
    "            p2 = obj2.centroid\n",
    "        elif type(obj1) == Point:\n",
    "            p2 = obj2\n",
    "        \n",
    "        return sqrt((p2.x-p1.x)**2 + (p2.y-p1.y)**2)\n",
    "    \n",
    "    @staticmethod\n",
    "    def jaccard(obj1, obj2):\n",
    "        \n",
    "        if type(obj1) == Box and type(obj2) == Box:\n",
    "            box1, box2 = obj1, obj2\n",
    "            \n",
    "            w_intersection = min(box1.x + box1.w, box2.x + box2.w) - max(box1.x, box2.x)\n",
    "            h_intersection = min(box1.y + box1.h, box2.y + box2.y) - max(box1.y, box2.y)\n",
    "            if w_intersection <= 0 or h_intersection <= 0: # No overlap\n",
    "                return 0\n",
    "            I = w_intersection * h_intersection\n",
    "            U = self.w * self.h + box.w * box.h - I # Union = Total Area - I\n",
    "            return I / U\n",
    "    \n",
    "        elif type(obj1) == numpy.ndarray and type(obj2) == numpy.ndarray:\n",
    "            descriptors1, descriptors2 = obj1, obj2\n",
    "            \n",
    "            # brute force feature matching using manhattan distance\n",
    "        \n",
    "            bf = cv2.BFMatcher(cv2.NORM_L1, crossCheck=True)\n",
    "\n",
    "            matches = bf.match(descriptors_1,descriptors_2)\n",
    "            matches = sorted(matches, key = lambda x:x.distance)\n",
    "\n",
    "            # TODO do we want to cutoff at a threshold?\n",
    "\n",
    "            return len(matches) / (len(descriptors1)+len(descriptors2))\n",
    "    \n",
    "    @staticmethod\n",
    "    def sift(box1, box2, img_path, frame_a_id, frame_b_id, new_w=tracking_config['scaled_width'], new_h=tracking_config['scaled_height']):\n",
    "        \n",
    "        # get filepaths\n",
    "        \n",
    "        img1_path = os.path.join(img_path, \"%06d.jpg\" % frame_a_id)\n",
    "        img2_path = os.path.join(img_path, \"%06d.jpg\" % frame_b_id)\n",
    "        \n",
    "        # read image files as grayscale\n",
    "        \n",
    "        img1 = cv2.imread(img1_path, 0)\n",
    "        img2 = cv2.imread(img2_path, 0)\n",
    "        \n",
    "        # gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "        # gray2 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # cut out the firt object from the first image\n",
    "        \n",
    "        top_left, bottom_right = box1.coords        \n",
    "        start_x, start_y = top_left\n",
    "        end_x, end_y = bottom_right        \n",
    "        crop1 = img1[start_y:end_y, start_x:end_x]\n",
    "        \n",
    "        # cut out the second object from the second image\n",
    "        \n",
    "        top_left, bottom_right = box2.coords        \n",
    "        start_x, start_y = top_left\n",
    "        end_x, end_y = bottom_right        \n",
    "        crop2 = img2[start_y:end_y, start_x:end_x]\n",
    "        \n",
    "#         # calculate the amount to scale in both directions\n",
    "        \n",
    "#         img_1_x_scale = new_w/box1.w\n",
    "#         img_1_y_scale = new_h/box1.h\n",
    "        \n",
    "#         img_1_x_scale = new_w/box2.w\n",
    "#         img_1_y_scale = new_h/box2.h\n",
    "        \n",
    "#         # resize both cropped images\n",
    "        \n",
    "#         scaled_img1 = cv2.resize(img1, None, fx=img_1_x_scale, fy=img_1_y_scale, interpolation = cv2.INTER_CUBIC)\n",
    "#         scaled_img2 = cv2.resize(img2, None, fx=img_2_x_scale, fy=img_2_y_scale, interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "        # TODO do I even need to scale? SIFT is Scale Invariant\n",
    "\n",
    "        scaled_img1 = cv2.resize(img1, (new_w, new_h), interpolation = cv2.INTER_CUBIC)\n",
    "        scaled_img2 = cv2.resize(img2, (new_w, new_h), interpolation = cv2.INTER_CUBIC)\n",
    "        \n",
    "        cv2.imshow(\"img1\", scaled_img1)\n",
    "        cv2.imshow(\"img2\", scaled_img2)\n",
    "        \n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        # find keypoints and descriptors\n",
    "        \n",
    "        # https://docs.opencv.org/4.3.0/da/df5/tutorial_py_sift_intro.html\n",
    "        \n",
    "        sift = cv2.xfeatures2d.SIFT_create()\n",
    "        \n",
    "        keypoints_1, descriptors_1 = sift.detectAndCompute(scaled_img1,None)\n",
    "        keypoints_2, descriptors_2 = sift.detectAndCompute(scaled_img2,None)\n",
    "\n",
    "        # brute force feature matching using manhattan distance\n",
    "        \n",
    "        bf = cv2.BFMatcher(cv2.NORM_L1, crossCheck=True)\n",
    "\n",
    "        matches = bf.match(descriptors_1,descriptors_2)\n",
    "        matches = sorted(matches, key = lambda x:x.distance)\n",
    "        \n",
    "        # TODO do we want to cutoff at a threshold?\n",
    "        \n",
    "        pprint(matches)\n",
    "        pprint(keypoints1)\n",
    "        pprint(keypoints2)\n",
    "        \n",
    "        return len(matches) / (len(descriptors_1)+len(descriptors_2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Box(object):\n",
    "    def __init__(self, x, y, w, h, frame=None, index=None):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.w = w\n",
    "        self.h = h\n",
    "        self.frame = frame\n",
    "        self.index = index\n",
    "    \n",
    "    @property\n",
    "    def coords(self):\n",
    "        return(Point(self.x, self.y), Point(self.x+self.w, self.y-self.h))\n",
    "    \n",
    "    @property\n",
    "    def centroid(self):\n",
    "        return Point(x+(w*0.5), y-(h*0.5))\n",
    "    \n",
    "    # TODO: move the similarity/distance calculation out of Box, doesn't belong here\n",
    "    \n",
    "    def jaccard(self, box):\n",
    "        w_intersection = min(self.x + self.w, box.x + box.w) - max(self.x, box.x)\n",
    "        h_intersection = min(self.y +self.h, box.y + box.y) - max(self.y, box.y)\n",
    "        if w_intersection <= 0 or h_intersection <= 0: # No overlap\n",
    "            return 0\n",
    "        I = w_intersection * h_intersection\n",
    "        U = self.w * self.h + box.w * box.h - I # Union = Total Area - I\n",
    "        return I / U\n",
    "\n",
    "    def copy(self, offset_x=0, offset_y=0):\n",
    "        return Box(\n",
    "            self.x + offset_x, \n",
    "            self.y + offset_y, \n",
    "            self.w, self.h, \n",
    "            self.frame, self.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Track(object):\n",
    "    counter = 1\n",
    "    \n",
    "    def __init__(self, boxes):\n",
    "        self.id = Track.counter\n",
    "        Track.counter += 1\n",
    "        \n",
    "        if type(boxes) == list:\n",
    "            self.boxes = boxes\n",
    "        elif type(boxes) == Bpx:\n",
    "            self.boxes = [box]\n",
    "            \n",
    "        self.is_active = True\n",
    "    \n",
    "    def add(self, box):\n",
    "        self.boxes.append(box)\n",
    "    \n",
    "    @staticmethod\n",
    "    def angle(box1, box2):\n",
    "        if len(self.boxes==1):\n",
    "            return None\n",
    "        previous, current = self.boxes[:-2]\n",
    "        \n",
    "        p1 = previous.centroid\n",
    "        p2 = previous.centroid\n",
    "\n",
    "        rads = math.atan2(p1.y-p2.y, p1.x-p2.x)\n",
    "        # deg = math.degrees(rads)\n",
    "        # return rads\n",
    "        return rads\n",
    "    \n",
    "    @staticmethod\n",
    "    def distance(box1, box2):\n",
    "        if len(self.boxes==1):\n",
    "            return None\n",
    "        previous, current = self.boxes[:-2]\n",
    "        \n",
    "        p1 = previous.centroid\n",
    "        p2 = current.centroid\n",
    "    \n",
    "        distance = math.hypot((p2.x-p1.x),(p2.y-p1.y))\n",
    "        # distance = sqrt((x2-x1)**2 + (y2-y1)**2)\n",
    "        \n",
    "        return distance\n",
    "    \n",
    "    def predict(self, frame):\n",
    "        current = self.boxes[-1:]\n",
    "        \n",
    "        if current.frame + 1 != frame:\n",
    "            return None\n",
    "        \n",
    "        if len(self.boxes==1):\n",
    "            predicted_location = current.copy()\n",
    "        else:\n",
    "            previous = self.boxes[-2:-1]\n",
    "            \n",
    "            angle = Track.angle(previous, current)\n",
    "            distance = Track.distance(previous, current)\n",
    "            \n",
    "            offset_x = distance*math.sin(angle)\n",
    "            offset_y = distance*math.cos(angle)\n",
    "            \n",
    "            predicted_location = current.copy(offset_x, offset_y)\n",
    "            \n",
    "        predicted_location.frame += 1\n",
    "\n",
    "        return predicted_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Frame(object):\n",
    "    def __init__(self, number, boxes=None):\n",
    "        self.id = number\n",
    "        \n",
    "        if boxes is None:\n",
    "            boxes = []\n",
    "        \n",
    "        self._boxes = boxes\n",
    "    \n",
    "    def add(self, box):\n",
    "        if type(box) == Box:\n",
    "            self._boxes.append(box)\n",
    "        elif type(box) == list:\n",
    "            self._boxes.extend(boxes)\n",
    "    \n",
    "    @property\n",
    "    def objects(object):\n",
    "        return self._boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Detections(object):\n",
    "    def __init__(self, data_path=tracking_config['detections_path']):\n",
    "        self.data_path = data_path\n",
    "        self._df = None\n",
    "        self._frames = {}\n",
    "        self.mean_width = None\n",
    "        self.mean_height = None\n",
    "    \n",
    "    def load(self, conf_threshold=tracking_config['confidence_threshold']):\n",
    "        \n",
    "        header_list = ['frame','trajectory','x','y','w','h','confidence']\n",
    "        dtype = {'frame':int,'trajectory':int,'x':float,'y':float,'w':float,'h':float,'confidence':float}\n",
    "        \n",
    "        df = pd.read_csv(data_path, names=header_list, dtype=dtype)\n",
    "        self._df = df[df[\"confidence\"] >= conf_threshold\n",
    "        \n",
    "        self.mean_width = df[\"w\"].mean()\n",
    "        self.mean_height = df[\"h\"].mean()\n",
    "\n",
    "        # get the indices for the first and last frames\n",
    "\n",
    "        start = df['frame'].min()\n",
    "        end = df['frame'].max()\n",
    "\n",
    "        for i in range(start, end):\n",
    "            self._frames[i] = df.loc[df['frame']==i,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trajectories(object):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self._tracks = []\n",
    "    \n",
    "    def add(self, o):\n",
    "        if type(o) == Box:\n",
    "            t = Track(o)\n",
    "            self._tracks[t.id] = t\n",
    "        if type(o) == Track:\n",
    "            self._tracks[o.id] = o\n",
    "    \n",
    "    def calculate(self, start=0, end=None):\n",
    "        if len(self._tracks==0):\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tracking(object):\n",
    "    def __init__(self):\n",
    "        self.detections = Detections()\n",
    "        self.trajectories = Trajectories()\n",
    "        self.detections.load()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
