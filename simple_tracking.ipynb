{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configparser import ConfigParser\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## constants\n",
    "############\n",
    "\n",
    "CONFIG_PATH = './conf/config.ini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## config\n",
    "#########\n",
    "\n",
    "config = ConfigParser()\n",
    "\n",
    "config.read(CONFIG_PATH)\n",
    "sequence_config = dict(config['Sequence'])\n",
    "tracking_config = dict(config['Tracking'])\n",
    "\n",
    "sequence_config['frame_rate'] = config.getint(\"Sequence\",\"frame_rate\")\n",
    "sequence_config['seq_length'] = config.getint(\"Sequence\",\"seq_length\")\n",
    "sequence_config['img_width'] = config.getint(\"Sequence\",\"img_width\")\n",
    "sequence_config['img_height'] = config.getint(\"Sequence\",\"img_height\")\n",
    "\n",
    "tracking_config['scaled_height'] = config.getint(\"Tracking\",\"scaled_height\")\n",
    "tracking_config['scaled_width'] = config.getint(\"Tracking\",\"scaled_width\")\n",
    "tracking_config['memory'] = config.getint(\"Tracking\",\"memory\")\n",
    "tracking_config['similarity_threshold'] = config.getfloat(\"Tracking\",\"similarity_threshold\")\n",
    "tracking_config['confidence_threshold'] = config.getfloat(\"Tracking\",\"confidence_threshold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## input\n",
    "########\n",
    "\n",
    "# pos       name                    description\n",
    "# 1      frame number           frame in which the object is present\n",
    "# 2      identity number        trajectory id (-1 default for no track)\n",
    "# 3      bounding box x         x value from top left of bounding box\n",
    "# 4      bounding box y         y value from top left of bounding box\n",
    "# 5      bounding box width     width of bounding box in pixels\n",
    "# 6      bounding box height    height of bounding box in pixels\n",
    "# 7      confidence score      class detection confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## output\n",
    "#########\n",
    "\n",
    "# pos       name                    description\n",
    "# 1      frame number           frame in which the object is present\n",
    "# 2      identity number        trajectory id (-1 default for no track)\n",
    "# 3      bounding box x         x value from top left of bounding box\n",
    "# 4      bounding box y         y value from top left of bounding box\n",
    "# 5      bounding box width     width of bounding box in pixels\n",
    "# 6      bounding box height    height of bounding box in pixels\n",
    "# 7      confidence score*      class detection confidence (gt: 1 or 0)\n",
    "# 8      class*                 type of class (1 for pedestrian)\n",
    "# 9      visibility*            percent visible (percent occluded = 1-visibility)\n",
    "\n",
    "#        *no need to output these values, will be ignore by evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Point(object):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Distance(object):\n",
    "    \n",
    "    @staticmethod\n",
    "    def l2_norm(obj1, obj2):\n",
    "        p1, p2 = None, None\n",
    "        \n",
    "        if type(obj1) == Box:\n",
    "            p1 = obj1.centroid\n",
    "        elif type(obj1) == Point:\n",
    "            p1 = obj1\n",
    "        \n",
    "        if type(obj1) == Box:\n",
    "            p2 = obj2.centroid\n",
    "        elif type(obj1) == Point:\n",
    "            p2 = obj2\n",
    "        \n",
    "        return math.sqrt((p2.x-p1.x)**2 + (p2.y-p1.y)**2)\n",
    "    \n",
    "    @staticmethod\n",
    "    def jaccard(obj1, obj2):\n",
    "        \n",
    "        if type(obj1) == Box and type(obj2) == Box:\n",
    "            box1, box2 = obj1, obj2\n",
    "            \n",
    "            w_intersection = min(box1.x + box1.w, box2.x + box2.w) - max(box1.x, box2.x)\n",
    "            h_intersection = min(box1.y + box1.h, box2.y + box2.y) - max(box1.y, box2.y)\n",
    "            if w_intersection <= 0 or h_intersection <= 0: # No overlap\n",
    "                return 0\n",
    "            I = w_intersection * h_intersection\n",
    "            U = box1.w * box1.h + box2.w * box2.h - I # Union = Total Area - I\n",
    "            return I / U\n",
    "    \n",
    "        elif type(obj1) == numpy.ndarray and type(obj2) == numpy.ndarray:\n",
    "            descriptors1, descriptors2 = obj1, obj2\n",
    "            \n",
    "            # brute force feature matching using manhattan distance\n",
    "        \n",
    "            bf = cv2.BFMatcher(cv2.NORM_L1, crossCheck=True)\n",
    "\n",
    "            matches = bf.match(descriptors_1,descriptors_2)\n",
    "            matches = sorted(matches, key = lambda x:x.distance)\n",
    "\n",
    "            # TODO do we want to cutoff at a threshold?\n",
    "\n",
    "            return len(matches) / (len(descriptors1)+len(descriptors2))\n",
    "    \n",
    "    @staticmethod\n",
    "    def sift(box1, box2, img_path, frame_a_id, frame_b_id, new_w=tracking_config['scaled_width'], new_h=tracking_config['scaled_height']):\n",
    "        \n",
    "        # get filepaths\n",
    "        \n",
    "        img1_path = os.path.join(img_path, \"%06d.jpg\" % frame_a_id)\n",
    "        img2_path = os.path.join(img_path, \"%06d.jpg\" % frame_b_id)\n",
    "        \n",
    "        # read image files as grayscale\n",
    "        \n",
    "        img1 = cv2.imread(img1_path, 0)\n",
    "        img2 = cv2.imread(img2_path, 0)\n",
    "        \n",
    "#         # gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "#         # gray2 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # cut out the firt object from the first image\n",
    "        \n",
    "        top_left, bottom_right = box1.coords        \n",
    "        start_x, start_y = top_left\n",
    "        end_x, end_y = bottom_right        \n",
    "        crop1 = img1[start_y:end_y, start_x:end_x]\n",
    "        \n",
    "        # cut out the second object from the second image\n",
    "        \n",
    "        top_left, bottom_right = box2.coords        \n",
    "        start_x, start_y = top_left\n",
    "        end_x, end_y = bottom_right        \n",
    "        crop2 = img2[start_y:end_y, start_x:end_x]\n",
    "        \n",
    "#         # calculate the amount to scale in both directions\n",
    "        \n",
    "#         img_1_x_scale = new_w/box1.w\n",
    "#         img_1_y_scale = new_h/box1.h\n",
    "        \n",
    "#         img_1_x_scale = new_w/box2.w\n",
    "#         img_1_y_scale = new_h/box2.h\n",
    "        \n",
    "#         # resize both cropped images\n",
    "        \n",
    "#         scaled_img1 = cv2.resize(img1, None, fx=img_1_x_scale, fy=img_1_y_scale, interpolation = cv2.INTER_CUBIC)\n",
    "#         scaled_img2 = cv2.resize(img2, None, fx=img_2_x_scale, fy=img_2_y_scale, interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "#         # TODO do I even need to scale? SIFT is Scale Invariant\n",
    "\n",
    "#         scaled_img1 = cv2.resize(img1, (new_w, new_h), interpolation = cv2.INTER_CUBIC)\n",
    "#         scaled_img2 = cv2.resize(img2, (new_w, new_h), interpolation = cv2.INTER_CUBIC)\n",
    "        \n",
    "#         cv2.imshow(\"img1\", scaled_img1)\n",
    "#         cv2.imshow(\"img2\", scaled_img2)\n",
    "        \n",
    "#         cv2.waitKey(0)\n",
    "#         cv2.destroyAllWindows()\n",
    "        \n",
    "        # find keypoints and descriptors\n",
    "        \n",
    "        # https://docs.opencv.org/4.3.0/da/df5/tutorial_py_sift_intro.html\n",
    "        \n",
    "        sift = cv2.xfeatures2d.SIFT_create()\n",
    "        \n",
    "        keypoints_1, descriptors_1 = sift.detectAndCompute(scaled_img1,None)\n",
    "        keypoints_2, descriptors_2 = sift.detectAndCompute(scaled_img2,None)\n",
    "\n",
    "        # brute force feature matching using manhattan distance\n",
    "        \n",
    "        bf = cv2.BFMatcher(cv2.NORM_L1, crossCheck=True)\n",
    "\n",
    "        matches = bf.match(descriptors_1,descriptors_2)\n",
    "        matches = sorted(matches, key = lambda x:x.distance)\n",
    "        \n",
    "        # TODO do we want to cutoff at a threshold?\n",
    "        \n",
    "        pprint(matches)\n",
    "        pprint(keypoints1)\n",
    "        pprint(keypoints2)\n",
    "        \n",
    "        return len(matches) / (len(descriptors_1)+len(descriptors_2))\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Box(object):\n",
    "    def __init__(self, x, y, w, h, index=None, frame=None, track_id=None, conf=None):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.w = w\n",
    "        self.h = h\n",
    "        self.frame = frame\n",
    "        self.index = index\n",
    "        self.track_id = track_id\n",
    "        self.conf = conf\n",
    "    \n",
    "    @property\n",
    "    def coords(self):\n",
    "        return(Point(self.x, self.y), Point(self.x+self.w, self.y+self.h))\n",
    "    \n",
    "    @property\n",
    "    def centroid(self):\n",
    "        return Point(self.x+(self.w*0.5), self.y+(self.h*0.5))\n",
    "    \n",
    "    # TODO: move the similarity/distance calculation out of Box, doesn't belong here\n",
    "    \n",
    "    def jaccard(self, box):\n",
    "        w_intersection = min(self.x + self.w, box.x + box.w) - max(self.x, box.x)\n",
    "        h_intersection = min(self.y + self.h, box.y + box.y) - max(self.y, box.y)\n",
    "        if w_intersection <= 0 or h_intersection <= 0: # No overlap\n",
    "            return 0\n",
    "        I = w_intersection * h_intersection\n",
    "        U = self.w * self.h + box.w * box.h - I # Union = Total Area - I\n",
    "        return I / U\n",
    "\n",
    "    def copy(self, offset_x=0, offset_y=0):\n",
    "        return Box(\n",
    "            self.x + offset_x, \n",
    "            self.y + offset_y, \n",
    "            self.w, self.h, \n",
    "            self.index, self.frame,\n",
    "            self.track_id, self.conf\n",
    "        )\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"Box(%s, %s, %s, %s, %s, %s, %s, %s)\" % (\n",
    "            self.x, self.y, self.w, self.h, self.index, self.frame, self.track_id, self.conf\n",
    "        )\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"index: %s, frame: %s, track: %s, x: %s, y: %s, w: %s, h: %s, conf: %s\" % (\n",
    "            self.index, self.frame, self.track_id, self.x, self.y, self.w, self.h, self.conf\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Track(object):\n",
    "    counter = 1\n",
    "    \n",
    "    def __init__(self, o):\n",
    "        self.id = Track.counter\n",
    "        Track.counter += 1\n",
    "        \n",
    "        if type(o) == list:\n",
    "            boxes = o\n",
    "            self.boxes = boxes\n",
    "        elif type(o) == Box:\n",
    "            box = o\n",
    "            self.boxes = [box]\n",
    "            \n",
    "        self.is_active = True\n",
    "    \n",
    "    def add(self, box):\n",
    "        box.track_id = self.id\n",
    "        self.boxes.append(box)\n",
    "    \n",
    "    @staticmethod\n",
    "    def angle(box1, box2):\n",
    "        \n",
    "        p1 = box1.centroid\n",
    "        p2 = box2.centroid\n",
    "\n",
    "        rads = math.atan2(p1.y-p2.y, p1.x-p2.x)\n",
    "        # deg = math.degrees(rads)\n",
    "        # return rads\n",
    "        return rads\n",
    "    \n",
    "    @staticmethod\n",
    "    def distance(box1, box2):\n",
    "            \n",
    "        p1 = box1.centroid\n",
    "        p2 = box2.centroid\n",
    "\n",
    "        distance = math.hypot((p2.x-p1.x),(p2.y-p1.y))\n",
    "        # distance = sqrt((x2-x1)**2 + (y2-y1)**2)\n",
    "        \n",
    "        return distance\n",
    "    \n",
    "    def predict(self, frame_id):\n",
    "        current = self.boxes[-1]\n",
    "        \n",
    "        if (frame_id - current.frame) > tracking_config['memory']:\n",
    "        # if current.frame != frame_id - 1:\n",
    "            return None\n",
    "        \n",
    "        if len(self.boxes)==1:\n",
    "            predicted_location = current.copy()\n",
    "        else:\n",
    "            previous = self.boxes[-2]\n",
    "            \n",
    "            angle = Track.angle(previous, current)\n",
    "            distance = Track.distance(previous, current)\n",
    "            \n",
    "            offset_x = distance*math.sin(angle)\n",
    "            offset_y = distance*math.cos(angle)\n",
    "            \n",
    "            # predicted_location = current.copy() # match last location\n",
    "            predicted_location = current.copy(offset_x, offset_y) # estimate trajectory\n",
    "            \n",
    "        predicted_location.frame += 1\n",
    "\n",
    "        return predicted_location\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"Track([<__main__.Box>]) count: %s\" % len(self.boxes)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"TrackID: %s, Frames: %s-%s\" % (\n",
    "            self.id, self.boxes[0].frame, self.boxes[-1].frame\n",
    "        )\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Frame(object):\n",
    "    def __init__(self, number, boxes=None):\n",
    "        self.id = number\n",
    "        \n",
    "        if boxes is None:\n",
    "            boxes = []\n",
    "        \n",
    "        self._boxes = boxes\n",
    "    \n",
    "    def add(self, box):\n",
    "        if type(box) == Box:\n",
    "            self._boxes.append(box)\n",
    "        elif type(box) == list:\n",
    "            self._boxes.extend(boxes)\n",
    "    \n",
    "    @property\n",
    "    def objects(self):\n",
    "        return self._boxes\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"Frame(%s, [<__main__.Box>]) count: %s\" % (self.id, len(self.boxes))\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"FrameID: %s, Count: %s\" % (self.id, len(self.boxes))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Detections(object):\n",
    "    def __init__(self, data_path=tracking_config['detections_path']):\n",
    "        self.data_path = data_path\n",
    "        self.mean_width = None\n",
    "        self.mean_height = None\n",
    "        self._df = None\n",
    "        self._frames = {}\n",
    "        self.start_index = None\n",
    "        self.end_index = None\n",
    "        self.count = sequence_config['seq_length']\n",
    "        self._pos = None\n",
    "        self._load()\n",
    "    \n",
    "    def _load(self, conf_threshold=tracking_config['confidence_threshold']):\n",
    "        \n",
    "        header_list = ['frame','trajectory','x','y','w','h','confidence']\n",
    "        dtype = {'frame':int,'trajectory':int,'x':float,'y':float,'w':float,'h':float,'confidence':float}\n",
    "        \n",
    "        df = pd.read_csv(self.data_path, names=header_list, dtype=dtype)\n",
    "\n",
    "        # filter out low confidence detections\n",
    "        \n",
    "        self._df = df[df[\"confidence\"] >= conf_threshold]\n",
    "        \n",
    "        self.mean_width = self._df[\"w\"].mean()\n",
    "        self.mean_height = self._df[\"h\"].mean()\n",
    "\n",
    "        # get the indices for the first and last frames\n",
    "\n",
    "        self.start_index = self._df['frame'].min()\n",
    "        self.end_index = self._df['frame'].max() + 1\n",
    "\n",
    "        for i in range(self.start_index, self.end_index):\n",
    "            self._frames[i] = self._df.loc[df['frame']==i,:]\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        return self.next()\n",
    "    \n",
    "    def next(self):\n",
    "        while True:\n",
    "            if self._pos is None:\n",
    "                self._pos = self.start_index        \n",
    "            elif self._pos < self.end_index:\n",
    "                current, self._pos = self._pos, self._pos + 1\n",
    "                current_frame = self._frames[current]\n",
    "\n",
    "                detection_boxes = []\n",
    "\n",
    "                for i, detection in current_frame.iterrows():                \n",
    "                    frame_no, traj_no, x, y, w, h, conf = detection\n",
    "                    box = Box(x, y, w, h, i, frame_no, -1, conf)\n",
    "                    detection_boxes.append(box)\n",
    "\n",
    "                return Frame(current, detection_boxes)\n",
    "            else:\n",
    "                # self._pos = None\n",
    "                raise StopIteration()\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \"Detections(%s, %s, %s, %s, %s, %s)\" % (\n",
    "            self.data_path, self.mean_width, self.mean_height, \n",
    "            self.start_index, self.end_index, self.count\n",
    "        )\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"path: %s, name: %s, mean_width: %s, mean_height: %s, start_index: %s, end_index: %s, count: %s)\" % (\n",
    "            self.data_path, sequence_config['name'], \n",
    "            self.mean_width, self.mean_height, \n",
    "            self.start_index, self.end_index, self.count\n",
    "        )\n",
    "    \n",
    "    def __len__(self):\n",
    "        # TODO this is really the length of the frames, that's how\n",
    "        # I use it in trajectories... should rethink this\n",
    "        return self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trajectories(object):\n",
    "    def __init__(self):\n",
    "        # reset track counter\n",
    "        Track.counter = 1\n",
    "        self._tracks = {}\n",
    "        self.detections = Detections()\n",
    "    \n",
    "    def add(self, o):\n",
    "        if type(o) == Box:\n",
    "            box = o\n",
    "            track = Track(box)\n",
    "            box.track_id = track.id\n",
    "            self._tracks[track.id] = track\n",
    "        if type(o) == Track:\n",
    "            track = o\n",
    "            self._tracks[track.id] = track\n",
    "    \n",
    "    def _matching(self, predictions, current_frame):\n",
    "        measure = tracking_config['distance_measure']\n",
    "        \n",
    "        if measure == 'euclidean':\n",
    "            distance_func = Distance.l2_norm\n",
    "        elif measure == 'iou':\n",
    "            distance_func = Distance.jaccard\n",
    "        else:\n",
    "            distance_func = Distance.sift\n",
    "            \n",
    "        sim_vector = []\n",
    "        computed = []\n",
    "        \n",
    "        for box_a in predictions:\n",
    "            for box_b in current_frame.objects:\n",
    "                \n",
    "                # WARNING this is kind of dangerous because index is not \n",
    "                # a required parameter for Box. Tracking computed pairs\n",
    "                # is meant to save time, but it might save too much time\n",
    "                # if box indices are None.\n",
    "                if box_a.index is None or box_b.index is None:\n",
    "                    raise Exception(\"Boundary index may not be None.\")                    \n",
    "                    \n",
    "                this_pair = set([box_a.index, box_b.index])\n",
    "                \n",
    "                if this_pair not in computed:\n",
    "                    # WARNING I think this is a problem because sift\n",
    "                    # has unique parameters (img, frame, etc)\n",
    "                    similarity = distance_func(box_a, box_b)\n",
    "                    \n",
    "                    if measure == 'euclidean':\n",
    "                        if similarity <= tracking_config['similarity_threshold']:\n",
    "                            sim_vector.append((similarity, box_a, box_b))\n",
    "                    else:\n",
    "                        if similarity >= tracking_config['similarity_threshold']:\n",
    "                            sim_vector.append((similarity, box_a, box_b))\n",
    "                        \n",
    "                    computed.append(this_pair)\n",
    "\n",
    "        if measure == 'euclidean':            \n",
    "            sim_vector.sort(key=lambda x: x[0])\n",
    "        else:\n",
    "            sim_vector.sort(reverse=True)\n",
    "\n",
    "        matching_pairs = []\n",
    "        matched_objects = set([])\n",
    "\n",
    "        for distance, box_1, box_2 in sim_vector:\n",
    "            \n",
    "            # we want to ensure that we only return the top matches, so we keep track\n",
    "            # of the objects already matched and ignore less similar matches for these objects\n",
    "            \n",
    "            if box_1.index not in matched_objects and box_2.index not in matched_objects:                \n",
    "            \n",
    "                match = (box_1, box_2)\n",
    "                matching_pairs.append(match)\n",
    "                \n",
    "                matched_objects.add(box_1.index)\n",
    "                matched_objects.add(box_2.index)\n",
    "        \n",
    "        # unmatched detections in current frame need to become new tracks\n",
    "        \n",
    "#         for box_b in current_frame.objects:\n",
    "#             if box_b.index not in matched_objects:\n",
    "#                 self.add(box_b)\n",
    "\n",
    "        # print(len(matched_objects), len(self._tracks))\n",
    "        \n",
    "        return matching_pairs\n",
    "    \n",
    "    def calculate(self, start=0, end=None):\n",
    "        if end is None:\n",
    "            end = len(self.detections)\n",
    "            \n",
    "        # for frame in self.detections[start:end]: # Detections not subscriptable\n",
    "        \n",
    "        for frame in self.detections:\n",
    "            # TODO fix this mess with dataframes\n",
    "            df = self.detections._frames[frame.id]\n",
    "            \n",
    "            if len(self._tracks)==0:\n",
    "                for box in frame.objects:\n",
    "                    self.add(box)\n",
    "                    \n",
    "                    # TODO fix this mess with dataframes\n",
    "                    df.loc[box.index, \"trajectory\"] = box.track_id\n",
    "                continue\n",
    "\n",
    "            predictions = []\n",
    "            for track_id, track in self._tracks.items():\n",
    "                prediction = track.predict(frame.id)\n",
    "                if prediction is not None:\n",
    "                    predictions.append(prediction)\n",
    "\n",
    "            matching_pairs = self._matching(predictions, frame)\n",
    "            for box_1, box_2 in matching_pairs:\n",
    "                track = self._tracks[box_1.track_id]\n",
    "                track.add(box_2)\n",
    "                \n",
    "                # TODO fix this mess with dataframes\n",
    "                df.loc[box_2.index, \"trajectory\"] = box_1.track_id\n",
    "\n",
    "    def output(self, path=None):\n",
    "        if path is None:            \n",
    "            for track_id, boxes in self._tracks.items():\n",
    "                print(track_id, boxes)\n",
    "        else:\n",
    "            # write\n",
    "            pass\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bosworth/anaconda3/envs/motaustin-env/lib/python3.6/site-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 TrackID: 1, Frames: 1.0-125.0\n",
      "2 TrackID: 2, Frames: 1.0-451.0\n",
      "3 TrackID: 3, Frames: 1.0-1050.0\n",
      "4 TrackID: 4, Frames: 1.0-390.0\n",
      "5 TrackID: 5, Frames: 1.0-543.0\n",
      "6 TrackID: 6, Frames: 1.0-1050.0\n",
      "7 TrackID: 7, Frames: 1.0-560.0\n",
      "8 TrackID: 8, Frames: 1.0-66.0\n",
      "9 TrackID: 9, Frames: 1.0-38.0\n",
      "10 TrackID: 10, Frames: 1.0-1050.0\n",
      "11 TrackID: 11, Frames: 1.0-756.0\n",
      "12 TrackID: 12, Frames: 1.0-385.0\n",
      "13 TrackID: 13, Frames: 1.0-1050.0\n",
      "14 TrackID: 14, Frames: 1.0-1050.0\n",
      "15 TrackID: 15, Frames: 1.0-1050.0\n",
      "16 TrackID: 16, Frames: 1.0-15.0\n",
      "17 TrackID: 17, Frames: 1.0-1050.0\n",
      "18 TrackID: 18, Frames: 1.0-520.0\n",
      "19 TrackID: 19, Frames: 1.0-174.0\n",
      "20 TrackID: 20, Frames: 1.0-635.0\n",
      "21 TrackID: 21, Frames: 1.0-220.0\n",
      "22 TrackID: 22, Frames: 1.0-1050.0\n",
      "23 TrackID: 23, Frames: 1.0-38.0\n",
      "24 TrackID: 24, Frames: 1.0-17.0\n",
      "25 TrackID: 25, Frames: 1.0-628.0\n",
      "26 TrackID: 26, Frames: 1.0-3.0\n"
     ]
    }
   ],
   "source": [
    "trajectories = Trajectories()\n",
    "trajectories.calculate()\n",
    "trajectories.output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "colors = []\n",
    "offset = 50\n",
    "for i in range(100):\n",
    "    r = randint(0,255)\n",
    "    g = randint(0,255)\n",
    "    b = randint(0,255)\n",
    "    \n",
    "    if r < offset or g < offset or b < offset:\n",
    "        colors.append(((r,g,b),(r+offset, g+offset, b+offset)))\n",
    "    else:\n",
    "        colors.append(((r,g,b),(r-offset, g-offset, b-offset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_frames = []\n",
    "img_path = \"img1\"\n",
    "\n",
    "img_filenames = [f for f in os.listdir(img_path) if os.path.isfile(os.path.join(img_path, f))]\n",
    "img_filenames.sort()\n",
    "\n",
    "for img_filename in img_filenames:\n",
    "    frame_id = int(img_filename.split('.')[0])\n",
    "    frame = trajectories.detections._frames[frame_id]\n",
    "    img = cv2.imread(os.path.join(img_path, img_filename))\n",
    "    for index, (frame,track,x,y,w,h,conf) in frame.iterrows():\n",
    "        \n",
    "        track, x, y, w, h = int(track), int(x), int(y), int(w), int(h)\n",
    "        if track < 1:\n",
    "            continue\n",
    "        \n",
    "        color_index = track % 100\n",
    "        box_color, text_color = colors[color_index]\n",
    "        \n",
    "        top_left = (x, y)\n",
    "        bottom_right = (x+w, y+h)\n",
    "        thickness = 2\n",
    "        \n",
    "        cv2.rectangle(img, top_left, bottom_right, box_color, thickness)\n",
    "        \n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        anchor_point = (x, y+20)\n",
    "        scale = 0.75\n",
    "        thickness = 2\n",
    "        line_type = cv2.LINE_AA\n",
    "        \n",
    "        cv2.putText(img, str(track), anchor_point, font, scale, text_color, thickness, line_type)\n",
    "        \n",
    "    video_frames.append(img)\n",
    "\n",
    "############ debug\n",
    "first, second, third = video_frames[:3]\n",
    "cv2.imwrite('output/first.jpg', first) \n",
    "cv2.imwrite('output/second.jpg', second) \n",
    "cv2.imwrite('output/third.jpg', third) \n",
    "##################\n",
    "\n",
    "output_path = 'output/%s.mp4' % tracking_config['out_seq_name']\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "fps = 30.0\n",
    "width = 1920\n",
    "height = 1080\n",
    "video_writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "for video_frame in video_frames:\n",
    "    video_writer.write(video_frame)\n",
    "\n",
    "video_writer.release()\n",
    "video_frames.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
