{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from configparser import ConfigParser\n",
    "import cv2\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## constants\n",
    "############\n",
    "\n",
    "CONFIG_PATH = './conf/config.ini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## config\n",
    "#########\n",
    "\n",
    "config = ConfigParser()\n",
    "\n",
    "config.read(CONFIG_PATH)\n",
    "sequence_config = dict(config['Sequence'])\n",
    "tracking_config = dict(config['Tracking'])\n",
    "\n",
    "sequence_config['frame_rate'] = config.getint(\"Sequence\",\"frame_rate\")\n",
    "sequence_config['seq_length'] = config.getint(\"Sequence\",\"seq_length\")\n",
    "sequence_config['img_width'] = config.getint(\"Sequence\",\"img_width\")\n",
    "sequence_config['img_height'] = config.getint(\"Sequence\",\"img_height\")\n",
    "\n",
    "tracking_config['scaled_height'] = config.getint(\"Tracking\",\"scaled_height\")\n",
    "tracking_config['scaled_width'] = config.getint(\"Tracking\",\"scaled_width\")\n",
    "tracking_config['memory'] = config.getint(\"Tracking\",\"memory\")\n",
    "tracking_config['similarity_threshold'] = config.getfloat(\"Tracking\",\"similarity_threshold\")\n",
    "tracking_config['distance_threshold'] = config.getfloat(\"Tracking\",\"distance_threshold\")\n",
    "tracking_config['confidence_threshold'] = config.getfloat(\"Tracking\",\"confidence_threshold\")\n",
    "\n",
    "\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "bf = cv2.BFMatcher(cv2.NORM_L1, crossCheck=True)\n",
    "\n",
    "# FLANN parameters\n",
    "FLANN_INDEX_KDTREE = 0\n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "search_params = dict(checks=50)   # or pass empty dictionary\n",
    "\n",
    "flann = cv2.FlannBasedMatcher(index_params,search_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## input\n",
    "########\n",
    "\n",
    "# pos       name                    description\n",
    "# 1      frame number           frame in which the object is present\n",
    "# 2      identity number        trajectory id (-1 default for no track)\n",
    "# 3      bounding box x         x value from top left of bounding box\n",
    "# 4      bounding box y         y value from top left of bounding box\n",
    "# 5      bounding box width     width of bounding box in pixels\n",
    "# 6      bounding box height    height of bounding box in pixels\n",
    "# 7      confidence score      class detection confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## output\n",
    "#########\n",
    "\n",
    "# pos       name                    description\n",
    "# 1      frame number           frame in which the object is present\n",
    "# 2      identity number        trajectory id (-1 default for no track)\n",
    "# 3      bounding box x         x value from top left of bounding box\n",
    "# 4      bounding box y         y value from top left of bounding box\n",
    "# 5      bounding box width     width of bounding box in pixels\n",
    "# 6      bounding box height    height of bounding box in pixels\n",
    "# 7      confidence score*      class detection confidence (gt: 1 or 0)\n",
    "# 8      class*                 type of class (1 for pedestrian)\n",
    "# 9      visibility*            percent visible (percent occluded = 1-visibility)\n",
    "\n",
    "#        *no need to output these values, will be ignore by evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Point(object):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Distance(object):\n",
    "    \n",
    "    @staticmethod\n",
    "    def l2_norm(obj1, obj2):\n",
    "        p1, p2 = None, None\n",
    "        \n",
    "        if type(obj1) == Box:\n",
    "            p1 = obj1.centroid\n",
    "        elif type(obj1) == Point:\n",
    "            p1 = obj1\n",
    "        \n",
    "        if type(obj1) == Box:\n",
    "            p2 = obj2.centroid\n",
    "        elif type(obj1) == Point:\n",
    "            p2 = obj2\n",
    "        \n",
    "        return math.sqrt((p2.x-p1.x)**2 + (p2.y-p1.y)**2)\n",
    "    \n",
    "    @staticmethod\n",
    "    def jaccard(obj1, obj2):\n",
    "        \n",
    "        if type(obj1) == Box and type(obj2) == Box:\n",
    "            \n",
    "            # just to make this a little more intuitive\n",
    "            box1, box2 = obj1, obj2\n",
    "            \n",
    "            # to make this easier we'll create two arrays, [x1, y1, x2, y2], s.t.\n",
    "            # (x1, y1) is the top left point for a box and (x2, y2) is the bottom right\n",
    "            a = [box1.x, box1.y, box1.x + box1.w, box1.y + box1.h]\n",
    "            b = [box2.x, box2.y, box2.x + box2.w, box2.y + box2.h]\n",
    "            \n",
    "            # intersection\n",
    "            \n",
    "            # find the boundary of the intersection between the two boxes\n",
    "            x1 = max(a[0], b[0]) # rightmost x of the top left points\n",
    "            y1 = max(a[1], b[1]) # lowest y of the top left points\n",
    "            x2 = min(a[2], b[2]) # leftmost x of the bottom right points\n",
    "            y2 = min(a[3], b[3]) # highest y of the bottom right points\n",
    "            \n",
    "            # find the area of the intersection\n",
    "            width = (x2 - x1)\n",
    "            height = (y2 - y1)\n",
    "            \n",
    "            # if no overlap don't bother going further, return 0\n",
    "            if width <= 0 or height <= 0:\n",
    "                return 0\n",
    "            \n",
    "            area_of_intersection = width * height\n",
    "            \n",
    "            # area of union\n",
    "            \n",
    "            # this is easy, you don't need to know where the boxes are, since you've\n",
    "            # already calculated the intersection. if you just add the total area\n",
    "            # of box_a and the the area of box_b you've counted the intersection\n",
    "            # twice, so just subtract the intersection once and you have the answer\n",
    "            a_area = (a[2] - a[0]) * (a[3] - a[1])\n",
    "            b_area = (b[2] - b[0]) * (b[3] - b[1])\n",
    "            \n",
    "            area_of_union = a_area + b_area - area_of_intersection\n",
    "            \n",
    "            # protect again division by zero\n",
    "            epsilon = 1e-5\n",
    "            \n",
    "            iou = area_of_intersection / (area_of_union + epsilon)\n",
    "            return iou\n",
    "    \n",
    "        elif type(obj1) == numpy.ndarray and type(obj2) == numpy.ndarray:\n",
    "            descriptors1, descriptors2 = obj1, obj2\n",
    "            \n",
    "            # brute force feature matching using manhattan distance\n",
    "        \n",
    "            bf = cv2.BFMatcher(cv2.NORM_L1, crossCheck=True)\n",
    "\n",
    "            matches = bf.match(descriptors_1, descriptors_2)\n",
    "            matches = sorted(matches, key = lambda x:x.distance)\n",
    "\n",
    "            # TODO do we want to cutoff at a threshold?\n",
    "            \n",
    "            intersection = len(matches)\n",
    "            union = len(descriptors1)+len(descriptors2)-intersection\n",
    "\n",
    "            epsilon = 1e-5\n",
    "            \n",
    "            return intersection / (union+epsilon)\n",
    "    \n",
    "    @staticmethod\n",
    "    def sift(box1, box2):\n",
    "        \n",
    "        img_path = sequence_config['img_path']\n",
    "        \n",
    "        # get filepaths\n",
    "        \n",
    "        img1_path = os.path.join(img_path, \"%06d.jpg\" % box1.frame)\n",
    "        img2_path = os.path.join(img_path, \"%06d.jpg\" % box2.frame)\n",
    "        \n",
    "        # read image files as grayscale\n",
    "        \n",
    "        color_img1 = cv2.imread(img1_path)\n",
    "        color_img2 = cv2.imread(img2_path)\n",
    "        \n",
    "        gray_img1 = cv2.cvtColor(color_img1, cv2.COLOR_BGR2GRAY)\n",
    "        gray_img2 = cv2.cvtColor(color_img1, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # cut out the firt object from the first image\n",
    "        \n",
    "        p1, p2 = box1.coords\n",
    "        start_x, start_y = int(round(p1.x)), int(round(p1.y))\n",
    "        end_x, end_y = int(round(p2.x)),int(round(p2.y))\n",
    "        \n",
    "        crop1 = gray_img1[start_y:end_y, start_x:end_x]\n",
    "        \n",
    "        # cut out the second object from the second image\n",
    "        \n",
    "        p1, p2 = box2.coords\n",
    "        start_x, start_y = int(round(p1.x)), int(round(p1.y))\n",
    "        end_x, end_y = int(round(p2.x)),int(round(p2.y))\n",
    "        \n",
    "        crop2 = gray_img1[start_y:end_y, start_x:end_x]\n",
    "        \n",
    "        # TODO consider experimenting with sharpening, contrast\n",
    "        \n",
    "        # find keypoints and descriptors        \n",
    "        # https://docs.opencv.org/4.3.0/da/df5/tutorial_py_sift_intro.html\n",
    "        # https://www.analyticsvidhya.com/blog/2019/10/detailed-guide-powerful-sift-technique-image-matching-python/\n",
    "\n",
    "        try:\n",
    "            keypoints_1, descriptors_1 = sift.detectAndCompute(crop1,None)        \n",
    "            keypoints_2, descriptors_2 = sift.detectAndCompute(crop2,None)\n",
    "        except Exception as ex:\n",
    "            print(\"\\n\\nBox1: %s, \\nBox 2: %s\\n%s\\n\" % (str(box1), str(box2), str(ex)))                        \n",
    "            return 0 \n",
    "\n",
    "        # brute force feature matching using manhattan distance\n",
    "        # https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_feature2d/py_matcher/py_matcher.html\n",
    "        \n",
    "#         # FLANN parameters\n",
    "#         FLANN_INDEX_KDTREE = 0\n",
    "#         index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "#         search_params = dict(checks=100)   # or pass empty dictionary\n",
    "\n",
    "#         flann = cv2.FlannBasedMatcher(index_params,search_params)\n",
    "\n",
    "        try:\n",
    "            matches = flann.knnMatch(descriptors_1,descriptors_2,k=2)\n",
    "        except Exception as ex:\n",
    "            print(box1, keypoints_1, box2, keypoints_2)\n",
    "            return 0\n",
    "\n",
    "        # Need to draw only good matches, so create a mask\n",
    "        good_matches = []\n",
    "\n",
    "        # ratio test as per Lowe's paper\n",
    "        for i,(m,n) in enumerate(matches):\n",
    "            if m.distance < 0.7*n.distance:\n",
    "                good_matches.append(m)\n",
    "        \n",
    "        \n",
    "#         try:\n",
    "#             matches = [m for m in bf.match(descriptors_1,descriptors_2) if m.distance < 300]\n",
    "#             # matches = sorted(matches, key = lambda x:x.distance)            \n",
    "#         except:\n",
    "#             print(\"\\n\\nerror matching descriptors\\n%s\\n%s\\n%s\\n%s\\n%s\\n%s\\n\\n\" % (str(box1),str(box2),str(keypoints_1), str(descriptors_1),str(keypoints_2), str(descriptors_2)))            \n",
    "#             return 0\n",
    "        \n",
    "#         from statistics import mean, median\n",
    "#         distances = [m.distance for m in matches]\n",
    "#         try:\n",
    "#             print(\"min: %s, max: %s, mean: %s, median: %s\" % (min(distances),max(distances),mean(distances),median(distances)))        \n",
    "#         except:\n",
    "#             pass\n",
    "        \n",
    "        # find the jaccard coefficient for intersection over union (matches / descriptors)\n",
    "        \n",
    "        jaccard = 0        \n",
    "        epsilon = 1e-5\n",
    "        \n",
    "        jaccard = len(good_matches) / (len(descriptors_1)+len(descriptors_2)-len(matches)+epsilon)\n",
    "        \n",
    "\n",
    "        return jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Box(object):\n",
    "    def __init__(self, x, y, w, h, index=None, frame=None, track_id=None, conf=None):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.w = w\n",
    "        self.h = h\n",
    "        self.index = index\n",
    "        self.frame = frame\n",
    "        self.track_id = track_id\n",
    "        self.conf = conf\n",
    "    \n",
    "    @property\n",
    "    def coords(self):\n",
    "        return(Point(self.x, self.y), Point(self.x+self.w, self.y+self.h))\n",
    "    \n",
    "    @property\n",
    "    def centroid(self):\n",
    "        return Point(self.x+(self.w*0.5), self.y+(self.h*0.5))\n",
    "\n",
    "    def copy(self, offset_x=0, offset_y=0):\n",
    "        \n",
    "        # make sure you don't go outside the image bounds\n",
    "        # i'm sure there's a more elegant way of doing this\n",
    "        \n",
    "        x1, y1 = self.x+offset_x, self.y+offset_y\n",
    "        x2, y2 = x1+self.w, y1+self.h\n",
    "        \n",
    "        image_width = sequence_config['img_width']\n",
    "        image_height = sequence_config['img_height']\n",
    "        w, h = self.w, self.h\n",
    "        \n",
    "        if x1 < 0:\n",
    "            x1 = 0\n",
    "        if y1 < 0:\n",
    "            y1 = 0\n",
    "        if x2 > image_width:\n",
    "            w = image_width - self.x\n",
    "        if y2 > image_height:\n",
    "            h = image_height - self.y\n",
    "        \n",
    "        return Box(x1, y1, w, h, self.index, self.frame, self.track_id, self.conf)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"Box(%s, %s, %s, %s, %s, %s, %s, %s)\" % (\n",
    "            self.x, self.y, self.w, self.h, self.index, self.frame, self.track_id, self.conf\n",
    "        )\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"index: %s, frame: %s, track: %s, x: %s, y: %s, w: %s, h: %s, conf: %s\" % (\n",
    "            self.index, self.frame, self.track_id, self.x, self.y, self.w, self.h, self.conf\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Track(object):\n",
    "    counter = 1\n",
    "    \n",
    "    def __init__(self, o):\n",
    "        self.id = Track.counter\n",
    "        Track.counter += 1\n",
    "        \n",
    "        if type(o) == list:\n",
    "            boxes = o\n",
    "            self.boxes = boxes\n",
    "        elif type(o) == Box:\n",
    "            box = o\n",
    "            self.boxes = [box]\n",
    "            \n",
    "        self.is_active = True\n",
    "    \n",
    "    def add(self, box):\n",
    "        box.track_id = self.id\n",
    "        self.boxes.append(box)\n",
    "    \n",
    "    @staticmethod\n",
    "    def angle(box1, box2):\n",
    "        \n",
    "        p1 = box1.centroid\n",
    "        p2 = box2.centroid\n",
    "\n",
    "        rads = math.atan2(p1.y-p2.y, p1.x-p2.x)\n",
    "        # deg = math.degrees(rads)\n",
    "        # return rads\n",
    "        return rads\n",
    "    \n",
    "    @staticmethod\n",
    "    def distance(box1, box2):\n",
    "            \n",
    "        p1 = box1.centroid\n",
    "        p2 = box2.centroid\n",
    "\n",
    "        distance = math.hypot((p2.x-p1.x),(p2.y-p1.y))\n",
    "        # distance = sqrt((x2-x1)**2 + (y2-y1)**2)\n",
    "        \n",
    "        return distance\n",
    "    \n",
    "    def predict(self, frame_id):\n",
    "        end_of_track = self.boxes[-1] # this is the last box added to the track\n",
    "        \n",
    "        frames_since_last_match = frame_id - end_of_track.frame\n",
    "        \n",
    "        if frames_since_last_match > tracking_config['memory']:\n",
    "            # forget this track if it's outside the memory window\n",
    "            return None\n",
    "        \n",
    "        if len(self.boxes)==1:\n",
    "            predicted_location = end_of_track.copy()\n",
    "        else:\n",
    "            second_to_end = self.boxes[-2]\n",
    "            \n",
    "            angle = Track.angle(second_to_end, end_of_track)\n",
    "            distance = Track.distance(second_to_end, end_of_track)\n",
    "            \n",
    "            # experiment, let's decrease the motion with each missing detection\n",
    "            \n",
    "            if frames_since_last_match < 1:\n",
    "                \n",
    "                frames_since_last_match = 1\n",
    "                print(\"Why frames_since_last_match < 1? From predict method in Track class.\")\n",
    "                \n",
    "            if tracking_config['distance_measure'] == 'sift':\n",
    "                distance = 1\n",
    "            else:\n",
    "                distance = distance * 1/frames_since_last_match\n",
    "            \n",
    "            # end of experiment section\n",
    "            \n",
    "            offset_x = distance*math.sin(angle)\n",
    "            offset_y = distance*math.cos(angle)\n",
    "            \n",
    "            # predicted_location = current.copy() # match last location\n",
    "            predicted_location = end_of_track.copy(offset_x, offset_y) # estimate trajectory\n",
    "            \n",
    "        # predicted_location.frame += 1\n",
    "\n",
    "        return predicted_location\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"Track([<__main__.Box>]) count: %s\" % len(self.boxes)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"TrackID: %s, Frames: %s-%s\" % (\n",
    "            self.id, self.boxes[0].frame, self.boxes[-1].frame\n",
    "        )\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Frame(object):\n",
    "    def __init__(self, number, boxes=None):\n",
    "        self.id = number\n",
    "        \n",
    "        if boxes is None:\n",
    "            boxes = []\n",
    "        \n",
    "        self._boxes = boxes\n",
    "    \n",
    "    def add(self, box):\n",
    "        if type(box) == Box:\n",
    "            self._boxes.append(box)\n",
    "        elif type(box) == list:\n",
    "            self._boxes.extend(boxes)\n",
    "    \n",
    "    @property\n",
    "    def objects(self):\n",
    "        return self._boxes\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"Frame(%s, [<__main__.Box>]) count: %s\" % (self.id, len(self.boxes))\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"FrameID: %s, Count: %s\" % (self.id, len(self.boxes))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Detections(object):\n",
    "    def __init__(self, data_path=tracking_config['detections_path']):\n",
    "        self.data_path = data_path\n",
    "        self.mean_width = None\n",
    "        self.mean_height = None\n",
    "        self._df = None\n",
    "        self._frames = {}\n",
    "        self.start_index = None\n",
    "        self.end_index = None\n",
    "        self.count = sequence_config['seq_length']\n",
    "        self._pos = None\n",
    "        self._load()\n",
    "    \n",
    "    def _load(self, conf_threshold=tracking_config['confidence_threshold']):\n",
    "        \n",
    "        header_list = ['frame','trajectory','x','y','w','h','confidence']\n",
    "        dtype = {'frame':int,'trajectory':int,'x':float,'y':float,'w':float,'h':float,'confidence':float}\n",
    "        \n",
    "        df = pd.read_csv(self.data_path, names=header_list, dtype=dtype)\n",
    "\n",
    "        # filter out low confidence detections\n",
    "        \n",
    "        self._df = df[df[\"confidence\"] >= conf_threshold]\n",
    "        \n",
    "        self.mean_width = self._df[\"w\"].mean()\n",
    "        self.mean_height = self._df[\"h\"].mean()\n",
    "\n",
    "        # get the indices for the first and last frames\n",
    "\n",
    "        self.start_index = self._df['frame'].min()\n",
    "        self.end_index = self._df['frame'].max() + 1\n",
    "\n",
    "        for i in range(self.start_index, self.end_index):\n",
    "            self._frames[i] = self._df.loc[df['frame']==i,:]\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        return self.next()\n",
    "    \n",
    "    def next(self):\n",
    "        while True:\n",
    "            if self._pos is None:\n",
    "                self._pos = self.start_index        \n",
    "            elif self._pos < self.end_index:\n",
    "                current, self._pos = self._pos, self._pos + 1\n",
    "                current_frame = self._frames[current]\n",
    "\n",
    "                detection_boxes = []\n",
    "\n",
    "                for i, detection in current_frame.iterrows():                \n",
    "                    frame_no, traj_no, x, y, w, h, conf = detection\n",
    "                    box = Box(x, y, w, h, int(i), int(frame_no), -1, conf)\n",
    "                    detection_boxes.append(box)\n",
    "\n",
    "                return Frame(current, detection_boxes)\n",
    "            else:\n",
    "                # self._pos = None\n",
    "                raise StopIteration()\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \"Detections(%s, %s, %s, %s, %s, %s)\" % (\n",
    "            self.data_path, self.mean_width, self.mean_height, \n",
    "            self.start_index, self.end_index, self.count\n",
    "        )\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"path: %s, name: %s, mean_width: %s, mean_height: %s, start_index: %s, end_index: %s, count: %s)\" % (\n",
    "            self.data_path, sequence_config['name'], \n",
    "            self.mean_width, self.mean_height, \n",
    "            self.start_index, self.end_index, self.count\n",
    "        )\n",
    "    \n",
    "    def __len__(self):\n",
    "        # TODO this is really the length of the frames, that's how\n",
    "        # I use it in trajectories... should rethink this\n",
    "        return self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trajectories(object):\n",
    "    def __init__(self):\n",
    "        # reset track counter\n",
    "        Track.counter = 1\n",
    "        self._tracks = {}\n",
    "        self.detections = Detections()\n",
    "    \n",
    "    def add(self, o):\n",
    "        if type(o) == Box:\n",
    "            box = o\n",
    "            track = Track(box)\n",
    "            box.track_id = track.id\n",
    "            self._tracks[track.id] = track\n",
    "        if type(o) == Track:\n",
    "            track = o\n",
    "            self._tracks[track.id] = track\n",
    "    \n",
    "    def _sift_matching(self, predictions, current_frame):\n",
    "        measure = tracking_config['distance_measure']\n",
    "        \n",
    "        if measure != 'sift':\n",
    "            return self._measure(predictions, current_frame)\n",
    "                \n",
    "        similarity_vector = []\n",
    "        computed = []\n",
    "                \n",
    "        for box_a in predictions:\n",
    "            for box_b in current_frame.objects:\n",
    "                \n",
    "                if box_a.index is None or box_b.index is None:\n",
    "                    raise Exception(\"Boundary index may not be None.\")                    \n",
    "                    \n",
    "                this_pair = set([box_a.index, box_b.index])\n",
    "                \n",
    "                if this_pair not in computed:\n",
    "                    \n",
    "                    distance = Distance.l2_norm(box_a, box_b)                    \n",
    "                    distance_threshold = tracking_config['distance_threshold']\n",
    "                    similarity_threshold = tracking_config['similarity_threshold']\n",
    "                    \n",
    "                    if distance <= distance_threshold:                        \n",
    "                        similarity = Distance.sift(box_a, box_b)\n",
    "                        if similarity > similarity_threshold:\n",
    "                            \n",
    "                            # little experiment to help match dark low contrast patches\n",
    "                            distance_weight = 1 # multiplier to increase or decrease importance of distance\n",
    "                            similarity_weight = 3 # multiplier to increase or decrease importance of image similarity\n",
    "                            \n",
    "                            # i'm giving more weight to similarity because i really only want proximity\n",
    "                            # to dominate when sift fails to detect keypoints\n",
    "                            \n",
    "                            distance_ratio = (distance_threshold - distance) / distance_threshold\n",
    "                            \n",
    "                            mean_similarity = (\n",
    "                                ((similarity_weight*similarity + distance_weight*distance_ratio)) / (similarity_weight+distance_weight)\n",
    "                            )                            \n",
    "                            \n",
    "                            # similarity_vector.append((mean_similarity, box_a, box_b))\n",
    "                            similarity_vector.append((similarity, box_a, box_b))\n",
    "                        \n",
    "                    computed.append(this_pair)\n",
    "\n",
    "        similarity_vector.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        matching_pairs = []\n",
    "        matched_objects = set([])\n",
    "\n",
    "        for distance, box_1, box_2 in similarity_vector:\n",
    "            \n",
    "            # we want to ensure that we only return the top matches, so we keep track\n",
    "            # of the objects already matched and ignore less similar matches for these objects\n",
    "            \n",
    "            if box_1.index not in matched_objects and box_2.index not in matched_objects:                \n",
    "            \n",
    "                match = (box_1, box_2)\n",
    "                matching_pairs.append(match)\n",
    "                \n",
    "                matched_objects.add(box_1.index)\n",
    "                matched_objects.add(box_2.index)\n",
    "        \n",
    "        # unmatched detections in current frame need to become new tracks\n",
    "        \n",
    "        unmatched = set(\n",
    "            [box for box in current_frame.objects if box.index not in matched_objects]\n",
    "        )\n",
    "        \n",
    "        for box in unmatched:\n",
    "           self.add(box)\n",
    "        \n",
    "        print(\"%s/%s\" % (len(matching_pairs), len(self._tracks),), end =\" \")\n",
    "        \n",
    "        return matching_pairs\n",
    "    \n",
    "    def _matching(self, predictions, current_frame):\n",
    "        measure = tracking_config['distance_measure']\n",
    "        \n",
    "        if mesaure == 'sift':\n",
    "            distance_func = Distance.sift\n",
    "        elif measure == 'euclidean':\n",
    "            distance_func = Distance.l2_norm\n",
    "        elif measure == 'iou':\n",
    "            distance_func = Distance.jaccard\n",
    "        else:\n",
    "            return\n",
    "    \n",
    "        sim_vector = []\n",
    "        computed = []\n",
    "        \n",
    "        for box_a in predictions:\n",
    "            for box_b in current_frame.objects:\n",
    "                \n",
    "                if box_a.index is None or box_b.index is None:\n",
    "                    raise Exception(\"Boundary index may not be None.\")                    \n",
    "                    \n",
    "                this_pair = set([box_a.index, box_b.index])\n",
    "                \n",
    "                if this_pair not in computed:\n",
    "                    \n",
    "                    similarity = distance_func(box_a, box_b)\n",
    "                    \n",
    "                    sim_threshold = tracking_config['similarity_threshold']\n",
    "                    \n",
    "                    if measure == 'euclidean':\n",
    "                        if similarity <= sim_threshold:\n",
    "                            \n",
    "                            ### little experiment, let's make it a ratio #############\n",
    "                            similarity = (sim_threshold - similarity) /  sim_threshold\n",
    "                            ##########################################################\n",
    "                            \n",
    "                            sim_vector.append((similarity, box_a, box_b))\n",
    "                    else:\n",
    "                        if similarity >= sim_threshold:\n",
    "                            sim_vector.append((similarity, box_a, box_b))\n",
    "                        \n",
    "                    computed.append(this_pair)\n",
    "\n",
    "        if measure == 'euclidean':            \n",
    "            # sim_vector.sort(key=lambda x: x[0])\n",
    "            sim_vector.sort(key=lambda x: x[0], reverse=True)\n",
    "        else:\n",
    "            sim_vector.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # print([x[0] for x in sim_vector[::3]], end=\", \")\n",
    "            \n",
    "        matching_pairs = []\n",
    "        matched_objects = set([])\n",
    "\n",
    "        for distance, box_1, box_2 in sim_vector:\n",
    "            \n",
    "            # we want to ensure that we only return the top matches, so we keep track\n",
    "            # of the objects already matched and ignore less similar matches for these objects\n",
    "            \n",
    "            if box_1.index not in matched_objects and box_2.index not in matched_objects:                \n",
    "            \n",
    "                match = (box_1, box_2)\n",
    "                matching_pairs.append(match)\n",
    "                \n",
    "                matched_objects.add(box_1.index)\n",
    "                matched_objects.add(box_2.index)\n",
    "        \n",
    "        # unmatched detections in current frame need to become new tracks\n",
    "        \n",
    "        unmatched = set(\n",
    "            [box for box in current_frame.objects if box.index not in matched_objects]\n",
    "        )\n",
    "        \n",
    "        for box in unmatched:\n",
    "            self.add(box)\n",
    "        \n",
    "        print(len(self._tracks), end =\" \")\n",
    "        \n",
    "        return matching_pairs\n",
    "    \n",
    "    def calculate(self, start=0, end=None):\n",
    "        if end is None:\n",
    "            end = len(self.detections)\n",
    "            \n",
    "        # for frame in self.detections[start:end]: # Detections not subscriptable\n",
    "        \n",
    "        for frame in self.detections:\n",
    "            # TODO fix this mess with dataframes\n",
    "            df = self.detections._frames[frame.id]\n",
    "            \n",
    "            if len(self._tracks)==0:\n",
    "                for box in frame.objects:\n",
    "                    self.add(box)\n",
    "                    \n",
    "                    # TODO fix this mess with dataframes\n",
    "                    df.loc[box.index, \"trajectory\"] = box.track_id\n",
    "                continue\n",
    "\n",
    "            predictions = []\n",
    "            for track_id, track in self._tracks.items():\n",
    "                prediction = track.predict(frame.id)\n",
    "                if prediction is not None:\n",
    "                    predictions.append(prediction)\n",
    "\n",
    "            #matching_pairs = self._matching(predictions, frame)\n",
    "            matching_pairs = self._sift_matching(predictions, frame)\n",
    "            \n",
    "            for box_1, box_2 in matching_pairs:\n",
    "                track = self._tracks[box_1.track_id]\n",
    "                track.add(box_2)\n",
    "                \n",
    "                # TODO fix this mess with dataframes\n",
    "                df.loc[box_2.index, \"trajectory\"] = box_1.track_id\n",
    "\n",
    "    def output(self, path=None):\n",
    "        if path is None:            \n",
    "            for track_id, boxes in self._tracks.items():\n",
    "                print(track_id, boxes)\n",
    "        else:\n",
    "            # write\n",
    "            pass\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 "
     ]
    }
   ],
   "source": [
    "trajectories = Trajectories()\n",
    "trajectories.calculate()\n",
    "trajectories.output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "colors = []\n",
    "offset = 50\n",
    "for i in range(100):\n",
    "    r = randint(0,255)\n",
    "    g = randint(0,255)\n",
    "    b = randint(0,255)\n",
    "    \n",
    "    if r < offset or g < offset or b < offset:\n",
    "        colors.append(((r,g,b),(r+offset, g+offset, b+offset)))\n",
    "    else:\n",
    "        colors.append(((r,g,b),(r-offset, g-offset, b-offset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_frames = []\n",
    "img_path = \"img1\"\n",
    "\n",
    "img_filenames = [f for f in os.listdir(img_path) if os.path.isfile(os.path.join(img_path, f))]\n",
    "img_filenames.sort()\n",
    "\n",
    "for img_filename in img_filenames:\n",
    "    frame_id = int(img_filename.split('.')[0])\n",
    "    frame = trajectories.detections._frames[frame_id]\n",
    "    img = cv2.imread(os.path.join(img_path, img_filename))\n",
    "    for index, (frame,track,x,y,w,h,conf) in frame.iterrows():\n",
    "        \n",
    "        track, x, y, w, h = int(track), int(x), int(y), int(w), int(h)\n",
    "        if track < 1:\n",
    "            continue\n",
    "        \n",
    "        color_index = track % 100\n",
    "        box_color, text_color = colors[color_index]\n",
    "        \n",
    "        top_left = (x, y)\n",
    "        bottom_right = (x+w, y+h)\n",
    "        thickness = 2\n",
    "        \n",
    "        cv2.rectangle(img, top_left, bottom_right, box_color, thickness)\n",
    "        \n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        anchor_point = (x, y+20)\n",
    "        scale = 0.75\n",
    "        thickness = 2\n",
    "        line_type = cv2.LINE_AA\n",
    "        \n",
    "        cv2.putText(img, str(track), anchor_point, font, scale, text_color, thickness, line_type)\n",
    "        \n",
    "    video_frames.append(img)\n",
    "\n",
    "output_path = 'output/%s.mp4' % tracking_config['out_seq_name']\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "fps = 30.0\n",
    "width = 1920\n",
    "height = 1080\n",
    "video_writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "for video_frame in video_frames:\n",
    "    video_writer.write(video_frame)\n",
    "\n",
    "video_writer.release()\n",
    "video_frames.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
